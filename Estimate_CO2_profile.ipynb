{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37932aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, Convolution1D, Conv1D, \\\n",
    "    MaxPooling1D, UpSampling1D,Cropping1D, LSTM, RepeatVector,Activation, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d794d47",
   "metadata": {},
   "source": [
    "# Process description\n",
    "Below is the scheme of the pilot plant (adapted from Process summary, the ChemEng Discovery space, Imperial College London). There are six sampling points between stages, and all the sampling points are fed to the same gas analyzer. However, the gas analyzer can only process the sampling stream one at a time, i.e., at any given time, there is only one position that the gaseous $CO_2$ concentration is known.\n",
    "<img src=\"images/pilot_plant.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d536eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records in the spreadsheet are are already labelled\n",
    "data_path_list = glob.glob('./data/withLabel/1*.xlsx')\n",
    "list_of_origin_df=[]\n",
    "for i in range(len(data_path_list)):\n",
    "    xls = pd.ExcelFile(data_path_list[i])\n",
    "    data_df = pd.read_excel(xls, sheet_name=0, index_col=0, header = [0,1])\n",
    "    data_df.columns = data_df.columns.map(''.join)\n",
    "    data_df=data_df.rename_axis('time').reset_index()\n",
    "    tmp_name=list(data_df.columns)\n",
    "    tmp_name[-1]='label'\n",
    "    data_df.columns=tmp_name\n",
    "    list_of_origin_df.append(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e6f03",
   "metadata": {},
   "source": [
    "Labelled process record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0da692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>AT100(pH)</th>\n",
       "      <th>AT300(pH)</th>\n",
       "      <th>AT400(CO2 %)</th>\n",
       "      <th>FT100(kg/hr)</th>\n",
       "      <th>FT101(kg/hr)</th>\n",
       "      <th>FT102(kg/hr)</th>\n",
       "      <th>FT103(kg/hr)</th>\n",
       "      <th>FT104(kg/hr)</th>\n",
       "      <th>FT105(L/min)</th>\n",
       "      <th>...</th>\n",
       "      <th>TT400(0C)</th>\n",
       "      <th>TT401(0C)</th>\n",
       "      <th>TT402(0C)</th>\n",
       "      <th>TT403(0C)</th>\n",
       "      <th>TT404(0C)</th>\n",
       "      <th>TT410(0C)</th>\n",
       "      <th>TT411(0C)</th>\n",
       "      <th>TT412(0C)</th>\n",
       "      <th>TT413(0C)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-20 17:23:02</td>\n",
       "      <td>10.468116</td>\n",
       "      <td>10.856668</td>\n",
       "      <td>0.109407</td>\n",
       "      <td>49.641636</td>\n",
       "      <td>0</td>\n",
       "      <td>114.306496</td>\n",
       "      <td>253.188339</td>\n",
       "      <td>244.473846</td>\n",
       "      <td>0.076785</td>\n",
       "      <td>...</td>\n",
       "      <td>117.106621</td>\n",
       "      <td>116.955292</td>\n",
       "      <td>116.753510</td>\n",
       "      <td>22.537117</td>\n",
       "      <td>104.836342</td>\n",
       "      <td>22.658978</td>\n",
       "      <td>34.482868</td>\n",
       "      <td>36.524200</td>\n",
       "      <td>33.270100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-20 17:23:46</td>\n",
       "      <td>10.429050</td>\n",
       "      <td>10.856927</td>\n",
       "      <td>0.098878</td>\n",
       "      <td>49.669559</td>\n",
       "      <td>0</td>\n",
       "      <td>73.167267</td>\n",
       "      <td>253.357178</td>\n",
       "      <td>244.543427</td>\n",
       "      <td>0.076773</td>\n",
       "      <td>...</td>\n",
       "      <td>116.413254</td>\n",
       "      <td>116.233284</td>\n",
       "      <td>116.142960</td>\n",
       "      <td>22.537117</td>\n",
       "      <td>105.931946</td>\n",
       "      <td>22.678768</td>\n",
       "      <td>33.612118</td>\n",
       "      <td>35.468010</td>\n",
       "      <td>32.640736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-20 17:24:29</td>\n",
       "      <td>10.380840</td>\n",
       "      <td>10.868021</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>49.750290</td>\n",
       "      <td>0</td>\n",
       "      <td>30.941877</td>\n",
       "      <td>254.384949</td>\n",
       "      <td>244.684982</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>...</td>\n",
       "      <td>115.733566</td>\n",
       "      <td>115.700668</td>\n",
       "      <td>115.546623</td>\n",
       "      <td>22.537117</td>\n",
       "      <td>106.712189</td>\n",
       "      <td>22.689386</td>\n",
       "      <td>32.948505</td>\n",
       "      <td>34.523560</td>\n",
       "      <td>32.053650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-20 17:25:12</td>\n",
       "      <td>10.319781</td>\n",
       "      <td>10.888022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.734818</td>\n",
       "      <td>0</td>\n",
       "      <td>65.672806</td>\n",
       "      <td>254.687668</td>\n",
       "      <td>244.545029</td>\n",
       "      <td>0.076057</td>\n",
       "      <td>...</td>\n",
       "      <td>115.841347</td>\n",
       "      <td>115.708611</td>\n",
       "      <td>115.522621</td>\n",
       "      <td>22.537117</td>\n",
       "      <td>107.563896</td>\n",
       "      <td>22.699842</td>\n",
       "      <td>32.655727</td>\n",
       "      <td>33.851078</td>\n",
       "      <td>31.548174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-20 17:25:55</td>\n",
       "      <td>10.248368</td>\n",
       "      <td>10.903030</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>49.566025</td>\n",
       "      <td>0</td>\n",
       "      <td>15.200113</td>\n",
       "      <td>254.401810</td>\n",
       "      <td>244.331406</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>...</td>\n",
       "      <td>114.879135</td>\n",
       "      <td>114.479225</td>\n",
       "      <td>114.496765</td>\n",
       "      <td>22.537117</td>\n",
       "      <td>107.848602</td>\n",
       "      <td>22.714924</td>\n",
       "      <td>32.635029</td>\n",
       "      <td>33.495365</td>\n",
       "      <td>31.267054</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  AT100(pH)  AT300(pH)  AT400(CO2 %)  FT100(kg/hr)  \\\n",
       "0 2014-01-20 17:23:02  10.468116  10.856668      0.109407     49.641636   \n",
       "1 2014-01-20 17:23:46  10.429050  10.856927      0.098878     49.669559   \n",
       "2 2014-01-20 17:24:29  10.380840  10.868021      0.001587     49.750290   \n",
       "3 2014-01-20 17:25:12  10.319781  10.888022      0.000000     49.734818   \n",
       "4 2014-01-20 17:25:55  10.248368  10.903030      0.000364     49.566025   \n",
       "\n",
       "   FT101(kg/hr)  FT102(kg/hr)  FT103(kg/hr)  FT104(kg/hr)  FT105(L/min)  ...  \\\n",
       "0             0    114.306496    253.188339    244.473846      0.076785  ...   \n",
       "1             0     73.167267    253.357178    244.543427      0.076773  ...   \n",
       "2             0     30.941877    254.384949    244.684982      0.076896  ...   \n",
       "3             0     65.672806    254.687668    244.545029      0.076057  ...   \n",
       "4             0     15.200113    254.401810    244.331406      0.076959  ...   \n",
       "\n",
       "    TT400(0C)   TT401(0C)   TT402(0C)  TT403(0C)   TT404(0C)  TT410(0C)  \\\n",
       "0  117.106621  116.955292  116.753510  22.537117  104.836342  22.658978   \n",
       "1  116.413254  116.233284  116.142960  22.537117  105.931946  22.678768   \n",
       "2  115.733566  115.700668  115.546623  22.537117  106.712189  22.689386   \n",
       "3  115.841347  115.708611  115.522621  22.537117  107.563896  22.699842   \n",
       "4  114.879135  114.479225  114.496765  22.537117  107.848602  22.714924   \n",
       "\n",
       "   TT411(0C)  TT412(0C)  TT413(0C)  label  \n",
       "0  34.482868  36.524200  33.270100      1  \n",
       "1  33.612118  35.468010  32.640736      1  \n",
       "2  32.948505  34.523560  32.053650      1  \n",
       "3  32.655727  33.851078  31.548174      2  \n",
       "4  32.635029  33.495365  31.267054      2  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_origin_df[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd61c6",
   "metadata": {},
   "source": [
    "The measurements consist of 53 temperature transmitters, 12 pressure transmitters, 19 flow transmitters, 4 level transmitters, 2 pH analyzers and the previously discussed gas concentration analyzer. The measurements cover the pilot plant process including the elements shown in previous figure as well as the various gas handling and storage systems and the auxiliary processes. Key measurements of the absorber column include (with descriptions on the P&ID):\n",
    "\n",
    "* FT103: Flow transmitter, $CO_2$ lean amine solution, valid range 120-12000 kg/hr.\n",
    "* FT104: Flow transmitter, $CO_2$ lean amine solution, valid range 100-1600 kg/hr, connects in serial with FT103.\n",
    "* TT210: Temperature transmitter, temperature of $CO_2$ lean amine solution, K.\n",
    "* TT211: Temperature transmitter, temperature of $CO_2$ lean amine solution, K, connects in serial with TT210.\n",
    "* FT303: Flow transmitter, $N_2$ absorber inlet (volumetric) flowrate, valid range 38.7-575 kg/hr.\n",
    "* FT304: Flow transmitter, $N_2$ absorber inlet flowrate, valid range 4.4-438 kg/hr, connects in serial with FT303.\n",
    "* PT403: Pressure transmitter, $N_2$ absorber inlet pressure, valid range -1-4 barG.\n",
    "* TT304: Temperature transmitter, $N_2$ absorber inlet temperature, K.\n",
    "* FT301: Flow transmitter, $CO_2$ absorber inlet (volumetric) flowrate, valid range 7.14-71.4 kg/hr.\n",
    "* FT302: Flow transmitter, $CO_2$ absorber inlet flowrate, valid range 1.56-156 kg/hr, connects in serial with FT301.\n",
    "* PT402: Pressure transmitter, $CO_2$ absorber inlet pressure, valid range -1-4 barG.\n",
    "* TT104: Temperature transmitter, temperature of $N_2, CO_2$ mixture at absorber inlet, K.\n",
    "* PT111: Pressure transmitter, bottom of the absorber, valid range -1-4 barG.\n",
    "* PT403: Pressure transmitter, top of the absorber, valid range -1-4 barG.\n",
    "\n",
    "Note the pressure transmitter of $N_2$ and of the top of the absorber is the same. The lean gas ($N_2$) is recycled from top of the absorber and mix with the $CO_2$, and forms the $CO_2$-rich feed gas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f59cd",
   "metadata": {},
   "source": [
    "# Kinetic (dynamic) modeling\n",
    "Instead of implementing complicated kinetic correlations, we fit a pseudo reaction to approximate the absorption process\n",
    "$CO_{2,(g)} + MEA_{(l)} \\underset{reaction_2}{\\stackrel{reaction_1}{\\rightleftharpoons}} \\left[ CO_2-MEA\\right]_{binded_{(l)}}$\n",
    "\n",
    "$R_1 = k_1 \\cdot \\exp^{\\frac{-E_{A1}}{8.314\\left(\\alpha_1\\cdot T +\\beta_1\\right)}}$,\n",
    "$R_2 = k_2 \\cdot \\exp^{\\frac{-E_{A2}}{8.314\\left(\\alpha_2\\cdot T+\\beta_2\\right)}}$,\n",
    "\n",
    "The vector of parameters are combined as x0 = [$k_1, \\alpha_1, \\beta_1, k_2, \\alpha_2, \\beta_2$]\n",
    "\n",
    "kinetic_model contains the Simulink model of the absorber. Please note that the parameters in the Simulink model are outdated and need to be run by Matlab script to update these parameters.\n",
    "The result_generation ran the kinetic_model with the fitted parameter: x0=[500.6,1,1005.5,4380,1,1263]. The results are tagged as \"time stamp.csv\". A schematic of the Simulink model is shown below:\n",
    "\n",
    "<img src=\"images/kinetic_scheme.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a304d7",
   "metadata": {},
   "source": [
    "# data-driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0880690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED']=str(0)\n",
    "    tf.random.set_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "\n",
    "def avgOutPoint1(df):\n",
    "    #Change point 1 readings to Avg. of Point 2.\n",
    "    label_list=list(df['label'])\n",
    "    conc_list = list(df['AT400(CO2 %)'])\n",
    "    p=0\n",
    "    num=0\n",
    "    i=0\n",
    "    sampling2_avgcon = list()\n",
    "    while i<len(label_list):\n",
    "        if label_list[i]==2:\n",
    "            p=p+conc_list[i]\n",
    "            num=num+1\n",
    "            i=i+1\n",
    "        else:\n",
    "            if p ==0 and num==0:\n",
    "                i=i+1\n",
    "                pass\n",
    "            else:\n",
    "                sampling2_avgcon.append(p/num)\n",
    "                i =i+1\n",
    "                num=0\n",
    "                p=0\n",
    "\n",
    "    i=0\n",
    "    k=-1\n",
    "    while i<(len(label_list)-1):\n",
    "        if label_list[i]==1:\n",
    "            conc_list[i]=sampling2_avgcon[k]\n",
    "            i=i+1\n",
    "        else:\n",
    "            if label_list[i+1]==1 :\n",
    "                k=k+1\n",
    "                i=i+1\n",
    "            else:\n",
    "                i=i+1\n",
    "    #set new AT400\n",
    "    df['AT400(CO2 %)']=pd.Series(data=conc_list,index=df.index)\n",
    "    return df\n",
    "\n",
    "def columnSeparator(df):\n",
    "    # linear interpolation to fill missing values\n",
    "    for i in range(1,7): # 6 sampling points\n",
    "        new_con =list()\n",
    "        j = 0\n",
    "        while j<df.shape[0]:\n",
    "            if df.iloc[j]['label']==i:\n",
    "                new_con.append( df.iloc[j]['AT400(CO2 %)'])\n",
    "                j = j+1\n",
    "            else:\n",
    "                new_con.append(np.nan)\n",
    "                j = j+1\n",
    "        df[str(i)+\"_sampling\"]=pd.Series(data=new_con,index=df.index)\n",
    "        df[str(i)+\"_sampling\"]=df[str(i)+\"_sampling\"].interpolate(method=\"linear\")\n",
    "    # Notice the df will contain NaN for the first few rows for each sampling point column\n",
    "    return df\n",
    "\n",
    "def getU(ens,reduced_dimension):\n",
    "    # assuming ens has shape of [sampe_size, sample_ravel()]\n",
    "    u, s, vh = np.linalg.svd(ens.T, full_matrices=False)\n",
    "    truncation_parameter = reduced_dimension\n",
    "    print('Truncation parameter: ',truncation_parameter)\n",
    "    u1=u[:,:truncation_parameter]\n",
    "    s1=s[:truncation_parameter]\n",
    "    vh1=vh[:truncation_parameter,:]\n",
    "    return u1\n",
    "\n",
    "def dfPOD(train_df_list, test_df_list, _train_feature_list, _label_list, reduced_dimension):\n",
    "    print('Train df(1st one) shape before POD: ', train_df_list[0].shape)\n",
    "    print('Test df(1st one) shape before POD: ', test_df_list[0].shape)\n",
    "    \n",
    "    label_list=_label_list.copy()\n",
    "    train_feature_list=_train_feature_list.copy()\n",
    "    #train_feature_list.remove('AT400(CO2 %)')\n",
    "    #label_list.append('AT400(CO2 %)')\n",
    "    \n",
    "    for i in range(len(train_df_list)):\n",
    "        if (i==0):\n",
    "            train_full_values=train_df_list[i][train_feature_list].values\n",
    "            train_label_values=train_df_list[i][label_list].values\n",
    "        else:\n",
    "            train_full_values=np.concatenate((train_full_values, train_df_list[i][train_feature_list].values), axis=0)\n",
    "            train_label_values=np.concatenate((train_label_values, train_df_list[i][label_list].values), axis=0)\n",
    "    for i in range(len(test_df_list)):\n",
    "        if (i==0):\n",
    "            test_full_values=test_df_list[i][train_feature_list].values\n",
    "            test_label_values=test_df_list[i][label_list].values\n",
    "        else:\n",
    "            test_full_values=np.concatenate((test_full_values, test_df_list[i][train_feature_list].values), axis=0)\n",
    "            test_label_values=np.concatenate((test_label_values, test_df_list[i][label_list].values), axis=0)\n",
    "    \n",
    "    n_set = train_full_values.shape[0]\n",
    "    train_index = list(set(range(0,n_set,1))- set(range(0,n_set,5)))\n",
    "    test_index = list(set(range(0,n_set,5)))\n",
    "    \n",
    "    x_train = train_full_values[train_index]; x_val = train_full_values[test_index]\n",
    "    x_test = test_full_values; \n",
    "\n",
    "    u1 = getU(x_train, reduced_dimension)\n",
    "\n",
    "    x_train_encoded = u1.T @ x_train.T # shape [truncation_parameter, sample size]\n",
    "    x_val_encoded = u1.T @ x_val.T\n",
    "    x_test_encoded = u1.T @ x_test.T\n",
    "\n",
    "    x_train_decoded = (u1 @ x_train_encoded).T # shape [sampe_size, sample_ravel()]\n",
    "    x_val_decoded = (u1 @ x_val_encoded).T\n",
    "    x_test_decoded = (u1 @ x_test_encoded).T\n",
    "    \n",
    "    print(\"Train: \", mean_squared_error(x_train,x_train_decoded));\n",
    "    print(\"Val: \", mean_squared_error(x_val,x_val_decoded));\n",
    "    print(\"Test: \", mean_squared_error(x_test,x_test_decoded));\n",
    "    \n",
    "    encoded_train= (u1.T @ train_full_values.T).T#.reshape(train_full_values.shape[0],train_full_values.shape[2])\n",
    "    encoded_test= (u1.T @ test_full_values.T).T#.reshape(test_full_values.shape[0],test_full_values.shape[2])\n",
    "    encoded_name_list=['encoded_{}'.format(i) for i in range(1,encoded_train.shape[1]+1)]\n",
    "    upper_index=0\n",
    "    bottom_index=0\n",
    "    for i in range(len(train_df_list)):\n",
    "        upper_index=bottom_index\n",
    "        bottom_index=upper_index+train_df_list[i].shape[0]\n",
    "        train_df_list[i]=pd.DataFrame(np.concatenate((encoded_train[upper_index:bottom_index,:],train_df_list[i][label_list].values),axis=1),\n",
    "                                     columns=encoded_name_list+label_list)\n",
    "    upper_index=0\n",
    "    bottom_index=0\n",
    "    for i in range(len(test_df_list)):\n",
    "        upper_index=bottom_index\n",
    "        bottom_index=upper_index+test_df_list[i].shape[0]\n",
    "        test_df_list[i]=pd.DataFrame(np.concatenate((encoded_test[upper_index:bottom_index,:],test_df_list[i][label_list].values),axis=1),\n",
    "                                     columns=encoded_name_list+label_list)\n",
    "    print('Train df(1st one) shape after AE: ', train_df_list[0].shape)\n",
    "    print('Test df(1st one) shape after AE: ', test_df_list[0].shape)\n",
    "    return train_df_list,test_df_list\n",
    "\n",
    "def dfAE(train_df_list, test_df_list, _train_feature_list, _label_list, reduced_dimension):\n",
    "    print('Train df(1st one) shape before AE: ', train_df_list[0].shape)\n",
    "    print('Test df(1st one) shape before AE: ', test_df_list[0].shape)\n",
    "    \n",
    "    label_list=_label_list.copy()\n",
    "    train_feature_list=_train_feature_list.copy()\n",
    "    #train_feature_list.remove('AT400(CO2 %)')\n",
    "    #label_list.append('AT400(CO2 %)')\n",
    "    \n",
    "    for i in range(len(train_df_list)):\n",
    "        if (i==0):\n",
    "            train_full_values=train_df_list[i][train_feature_list].values\n",
    "            train_label_values=train_df_list[i][label_list].values\n",
    "        else:\n",
    "            train_full_values=np.concatenate((train_full_values, train_df_list[i][train_feature_list].values), axis=0)\n",
    "            train_label_values=np.concatenate((train_label_values, train_df_list[i][label_list].values), axis=0)\n",
    "    for i in range(len(test_df_list)):\n",
    "        if (i==0):\n",
    "            test_full_values=test_df_list[i][train_feature_list].values\n",
    "            test_label_values=test_df_list[i][label_list].values\n",
    "        else:\n",
    "            test_full_values=np.concatenate((test_full_values, test_df_list[i][train_feature_list].values), axis=0)\n",
    "            test_label_values=np.concatenate((test_label_values, test_df_list[i][label_list].values), axis=0)\n",
    "    \n",
    "    n_set = train_full_values.shape[0]\n",
    "    train_index = list(set(range(0,n_set,1))- set(range(0,n_set,5)))\n",
    "    test_index = list(set(range(0,n_set,5)))\n",
    "    \n",
    "    x_train = train_full_values[train_index]; x_val = train_full_values[test_index]\n",
    "    x_test = test_full_values; \n",
    "    print('LSTM x_train shape: ', x_train.shape[0])\n",
    "\n",
    "    noise_factor = 0.1\n",
    "    scale_arr = np.var(x_train,axis=0)\n",
    "    x_train = x_train + noise_factor * np.random.normal(loc=0.0, scale=scale_arr, size=x_train.shape) \n",
    "    x_test = x_test + noise_factor * np.random.normal(loc=0.0, scale=scale_arr, size=x_test.shape) \n",
    "    x_train = np.clip(x_train, 0., 1.)\n",
    "    x_test = np.clip(x_test, 0., 1.)\n",
    "    # AE shape default design\n",
    "    input_img = Input(shape=(x_train.shape[1]))\n",
    "    x = Dense(64,activation='relu',kernel_initializer=ReLu)(input_img)\n",
    "    encoded = Dense(reduced_dimension,activation='relu',kernel_initializer=ReLu)(x)\n",
    "\n",
    "\n",
    "    encoder = Model(input_img, encoded)\n",
    "    encoder.summary()\n",
    "\n",
    "    decoder_input = Input(shape=(reduced_dimension))\n",
    "\n",
    "    x = Dense(64)(decoder_input)\n",
    "    decoded = Dense(x_train.shape[1], activation='sigmoid')(x)\n",
    "\n",
    "    decoder = Model(decoder_input, decoded)\n",
    "    decoder.summary()\n",
    "\n",
    "    encoder=Model(inputs=input_img, outputs=encoded, name = 'encoder')\n",
    "    decoder=Model(inputs=decoder_input, outputs=decoded, name = 'decoder')\n",
    "    autoencoder_outputs = decoder(encoder(input_img))\n",
    "    autoencoder= Model(input_img, autoencoder_outputs, name='autoencoder')\n",
    "    autoencoder.summary()\n",
    "    #Optimizers \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    autoencoder.compile(optimizer=opt, loss=\"mse\")\n",
    "\n",
    "    # Set callback functions to early stop training and save the best model so far\n",
    "    early_stopping_monitor = [EarlyStopping(monitor='val_loss', patience=30, verbose=0,restore_best_weights=True)]\n",
    "\n",
    "    history = autoencoder.fit(x_train, x_train, epochs=500, batch_size=40,shuffle=True, \n",
    "                              validation_data=(x_val, x_val), callbacks=early_stopping_monitor)\n",
    "    #loss: 0.0217 - val_loss: 0.0230 before adding dense\n",
    "    autoencoder.save(os.path.join('DAE'))\n",
    "    autoencoder=keras.models.load_model(os.path.join('DAE'))\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    print('Train: ',mean_squared_error(x_train,autoencoder.predict(x_train)))\n",
    "    print('Val: ',mean_squared_error(x_val,autoencoder.predict(x_val)))\n",
    "    print('Test: ',mean_squared_error(x_test,autoencoder.predict(x_test)))\n",
    "    \n",
    "    encoder = autoencoder.get_layer(\"encoder\")\n",
    "    encoded_train=encoder.predict(train_full_values)#.reshape(train_full_values.shape[0],train_full_values.shape[2])\n",
    "    encoded_test=encoder.predict(test_full_values)#.reshape(test_full_values.shape[0],test_full_values.shape[2])\n",
    "    encoded_name_list=['encoded_{}'.format(i) for i in range(1,encoded_train.shape[1]+1)]\n",
    "    upper_index=0\n",
    "    bottom_index=0\n",
    "    for i in range(len(train_df_list)):\n",
    "        upper_index=bottom_index\n",
    "        bottom_index=upper_index+train_df_list[i].shape[0]\n",
    "        train_df_list[i]=pd.DataFrame(np.concatenate((encoded_train[upper_index:bottom_index,:],train_df_list[i][label_list].values),axis=1),\n",
    "                                     columns=encoded_name_list+label_list)\n",
    "    upper_index=0\n",
    "    bottom_index=0\n",
    "    for i in range(len(test_df_list)):\n",
    "        upper_index=bottom_index\n",
    "        bottom_index=upper_index+test_df_list[i].shape[0]\n",
    "        test_df_list[i]=pd.DataFrame(np.concatenate((encoded_test[upper_index:bottom_index,:],test_df_list[i][label_list].values),axis=1),\n",
    "                                     columns=encoded_name_list+label_list)\n",
    "    print('Train df(1st one) shape after AE: ', train_df_list[0].shape)\n",
    "    print('Test df(1st one) shape after AE: ', test_df_list[0].shape)\n",
    "    return train_df_list,test_df_list\n",
    "\n",
    "def getSampleSet(df_list, callback, train_feature_list, label_list):\n",
    "    conc_label_list=[]\n",
    "    for i in range(len(df_list)):\n",
    "        # The 1st element in label list is label\n",
    "        nset = df_list[i].shape[0]-callback\n",
    "        print(\"Number of set: \", nset)\n",
    "        conc_input=np.zeros((df_list[i].shape[0],6)) # Only the true reading is non-zero\n",
    "        conc_set = df_list[i][label_list[1:]].values # Excl. 1st column, label column\n",
    "        conc_set[np.isnan(conc_set)]=0\n",
    "        parameter_set = df_list[i][train_feature_list].values\n",
    "        for k in range(conc_input.shape[0]): # Only the true reading is non-zero, default for onehot\n",
    "            conc_input[k][int(df_list[i]['label'][k])-1]=1        \n",
    "        conc_input[np.isnan(conc_input)]=0\n",
    "        parameter_set=np.hstack((parameter_set,conc_input))\n",
    "        sample_set=np.zeros((nset,callback+1,parameter_set.shape[1]))\n",
    "        label_set=np.zeros((nset,1,conc_set.shape[1]))\n",
    "        for j in range(nset):\n",
    "            sample_set[j]=parameter_set[0+j:callback+j+1]\n",
    "            label_set[j]=conc_set[callback+j]\n",
    "        \n",
    "        if (i==0):\n",
    "            total_sample_set=np.zeros((0,callback+1,parameter_set.shape[1]))\n",
    "            total_label_set=np.zeros((0,1,conc_set.shape[1]))\n",
    "        conc_label_list.append(label_set)\n",
    "        total_sample_set = np.vstack([total_sample_set,sample_set])\n",
    "        total_label_set = np.vstack([total_label_set,label_set])\n",
    "        \n",
    "    return total_sample_set, total_label_set, conc_label_list\n",
    "        \n",
    "\n",
    "def getDataSet(path_list,df_list, callback, test_df_index_list, mode, reduced_dimension):\n",
    "    # Pre-processing: avg. out Conc @ sampling point 1\n",
    "    print('Timestamp in selected Test df list: ')\n",
    "    for i in range(len(test_df_index_list)):\n",
    "        print(os.path.basename(path_list[test_df_index_list[i]]))\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i]=df_list[i].set_index('time')\n",
    "        #df_list[i]=df_list[i].drop(columns=[\"time\"])\n",
    "        df_list[i] = avgOutPoint1(df_list[i])\n",
    "        if (i==0):\n",
    "            origin_feature_num = df_list[i].shape[1]\n",
    "            print(\"Origin input DF feature num(excl time, incl. label): \", origin_feature_num)\n",
    "\n",
    "    # Separate df_list into Train & Test df lists\n",
    "    test_df_list = list(pd.Series(df_list)[test_df_index_list]) # The 140207_1 is selected as the testset\n",
    "    train_df_list = list(pd.Series(df_list)[list(set(range(0,len(df_list),1))-set(test_df_index_list))])\n",
    "\n",
    "    #Min-max scaler, calculated from train_df_list\n",
    "    for i in range(len(train_df_list)):\n",
    "        if (i==0):\n",
    "            tmp_full_values=train_df_list[i].values\n",
    "            tmp_conc_values=train_df_list[i]['AT400(CO2 %)'].values\n",
    "        else:\n",
    "            tmp_full_values=np.concatenate((tmp_full_values, train_df_list[i].values), axis=0)\n",
    "            tmp_conc_values=np.concatenate((tmp_conc_values, train_df_list[i]['AT400(CO2 %)'].values), axis=0)\n",
    "    tmp_full_values = tmp_full_values[:,:-1] # excl. label column as well\n",
    "    general_scaler = MinMaxScaler()\n",
    "    conc_scaler = MinMaxScaler()\n",
    "    general_scaler.fit(tmp_full_values)\n",
    "    conc_scaler.fit(tmp_conc_values.reshape(-1,1))\n",
    "\n",
    "    print('Conc scaler max: ',conc_scaler.data_max_)\n",
    "\n",
    "    # Process into + ['label', '1_sampling', '2_sampling', '3_sampling', '4_sampling', '5_sampling', '6_sampling']\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i].iloc[:,:-1] = general_scaler.transform(df_list[i].iloc[:,:-1].values)\n",
    "        df_list[i] = columnSeparator(df_list[i])\n",
    "        df_list[i]=df_list[i].fillna(0)\n",
    "\n",
    "    nan_num = 0\n",
    "    for df in df_list:\n",
    "        #print(df.dtypes)\n",
    "        avail_index = (df['6_sampling']>=0).argmax()\n",
    "        if (nan_num < avail_index):\n",
    "            nan_num = avail_index\n",
    "    print(\"Minimum call back is: \", nan_num+1)\n",
    "    if (nan_num+1<callback):\n",
    "        print('The smallest feasible callback is: ', nan_num+1)\n",
    "\n",
    "    # Separate df_list into Train & Test df lists\n",
    "    test_df_list = list(pd.Series(df_list)[test_df_index_list]) # The 140207_1 is selected as the testset\n",
    "    train_df_list = list(pd.Series(df_list)[list(set(range(0,len(df_list),1))-set(test_df_index_list))])\n",
    "\n",
    "    print(\"train list: \", len(train_df_list))\n",
    "    label_list=['label', '1_sampling', '2_sampling', '3_sampling', '4_sampling', '5_sampling', '6_sampling']\n",
    "    train_feature_list = list(np.sort(list(set(df_list[0].columns)-set(label_list))))\n",
    "    if (mode == 'PCA'):\n",
    "        if (reduced_dimension == 16):\n",
    "            train_feature_list = ['TT113(0C)','TT300(0C)','TT302(0C)','TT202(0C)','TT304(0C)',\"TT400(0C)\",\n",
    "                                  \"TT410(0C)\",'PT103(barg)','PT402(barg)','PT403(barg)','PT102(barg)' ,'AT300(pH)',\n",
    "                                  'FT302(kg/hr)', 'FT303m3/hr','FT304(kg/hr)','FT103(kg/hr)']\n",
    "        else:\n",
    "            train_feature_list = ['TT302(0C)','TT300(0C)','TT401(0C)','TT303(0C)','TT400(0C)','TT113(0C)',\n",
    "                                  'TT301(0C)','TT202(0C)','TT412(0C)','TT309(0C)','TT110a(0C)','TT410(0C)',\n",
    "                                  'TT112(0C)','PT103(barg)','PT402(barg)','PT401(barg)','TT404(0C)', 'TT214(0C)',\n",
    "                                  'FT304(kg/hr)','AT100(pH)','FT303m3/hr','AT300(pH)','FT105(L/min)','FT103(kg/hr)',\n",
    "                                  'PT403(barg)','TT304(0C)','FT301m3/hr','TT107(0C)', 'PT110(barg)','PT111(barg)',\n",
    "                                  'TT210(0C)','TT211(0C)']\n",
    "    if (mode == 'DAE'):\n",
    "        train_df_list, test_df_list=dfAE(train_df_list, test_df_list, train_feature_list, label_list, reduced_dimension)\n",
    "        train_feature_list = np.sort(list(set(train_df_list[0].columns)-set(label_list)))\n",
    "    if (mode == 'POD'):\n",
    "        train_df_list, test_df_list=dfPOD(train_df_list, test_df_list, train_feature_list, label_list, reduced_dimension)\n",
    "        train_feature_list = np.sort(list(set(train_df_list[0].columns)-set(label_list)))\n",
    "    train_sample_set, train_label_set,_ = getSampleSet(train_df_list, callback, train_feature_list, label_list)\n",
    "    test_sample_set, test_label_set,test_conc_list = getSampleSet(test_df_list, callback, train_feature_list, label_list)\n",
    "\n",
    "    \n",
    "    return train_sample_set, train_label_set, test_sample_set, test_label_set, conc_scaler, train_df_list, test_df_list, test_conc_list\n",
    "\n",
    "def GCfunc(i, j, corr_length):\n",
    "    r = abs(i-j)/corr_length\n",
    "    if (r>=0 and r<1):\n",
    "        return (1-pow(r,2)*5/3+pow(r,3)*5/8+pow(r,4)*0.5-pow(r,5)*0.25)\n",
    "    if (r>=1 and r<2):\n",
    "        return (4-5*r+pow(r,2)*5/3+pow(r,3)*5/8-pow(r,4)*0.5+pow(r,5)/12-2/3/r)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def covLoc(B, corr_length):\n",
    "    ls_size=B.shape[0]\n",
    "    for i in range(ls_size):\n",
    "        for j in range(ls_size):\n",
    "            B[i][j] = B[i][j]*GCfunc(i,j,corr_length)\n",
    "    return B\n",
    "\n",
    "def trainSequenceLSTM(state, train_sample_set, train_label_set, test_sample_set, test_label_set):\n",
    "    n_sequence = train_sample_set.shape[1]\n",
    "    n_feature = train_sample_set.shape[2]\n",
    "    n_set = train_sample_set.shape[0]\n",
    "    print('train_sample_set shape: ', train_sample_set.shape)\n",
    "    \n",
    "    train_index = list(set(range(0,n_set,1))- set(range(0,n_set,5)))\n",
    "    test_index = list(set(range(0,n_set,5)))\n",
    "    x_train = train_sample_set[train_index]; x_val = train_sample_set[test_index]\n",
    "    y_train = train_label_set[train_index]; y_val = train_label_set[test_index]\n",
    "    x_test = test_sample_set; y_test = test_label_set\n",
    "    print('Train len: %d, Val len: %d' %(x_train.shape[0], x_val.shape[0]))\n",
    "    print('x_train shape: '+str(x_train.shape)+ ', y_train shape:' + str(y_train.shape))\n",
    "\n",
    "    \n",
    "    if (state == 'train'):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100,input_shape=(n_sequence,n_feature), return_sequences=True))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(Dense(100))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(Dense(100))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "        \n",
    "        #Optimizers \n",
    "        #opt = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "        #model.compile(optimizer=opt, loss=my_loss_fn)\n",
    "        model.compile(optimizer=opt, loss='mse')\n",
    "        model.summary()\n",
    "        # Set callback functions to early stop training and save the best model so far\n",
    "        early_stopping_monitor = [EarlyStopping(monitor='val_loss', patience=70, verbose=0,restore_best_weights=True)]\n",
    "        \n",
    "        # fit model\n",
    "        train_log = model.fit(x_train, y_train, batch_size=40, epochs=500, shuffle=True, \n",
    "                               validation_data=(x_val, y_val), callbacks=early_stopping_monitor)\n",
    "        LSTM_model = model\n",
    "        #Note the label\n",
    "        model.save('LSTM_MSE.h5')\n",
    "\n",
    "        plt.plot(train_log.history['loss'])\n",
    "        plt.plot(train_log.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "    else:\n",
    "        model = keras.models.load_model('LSTM_MSE.h5')\n",
    "    \n",
    "    # Evaluate the model on the test data using `evaluate`\n",
    "    print(\"Evaluate on test data\")\n",
    "    #results = model.evaluate(x_test, y_test, batch_size=36)\n",
    "    predict_set=model.predict(x_test)\n",
    "    results = mean_squared_error(conc_scaler.inverse_transform(np.mean(predict_set,axis=1)),conc_scaler.inverse_transform(y_test.reshape(y_test.shape[0],6)))\n",
    "    print(\"MSE:\", results)\n",
    "    \n",
    "    val_output_set = model.predict(x_val)\n",
    "    \n",
    "    print(\"Evaluate on validation\")\n",
    "    results = mean_squared_error(conc_scaler.inverse_transform(np.mean(val_output_set,axis=1)),conc_scaler.inverse_transform(y_val.reshape(y_val.shape[0],6)))\n",
    "    print(\"MSE:\", results)\n",
    "    \n",
    "    R=np.cov((conc_scaler.inverse_transform(np.mean(val_output_set,axis=1))- \\\n",
    "              conc_scaler.inverse_transform(y_val.reshape(y_val.shape[0],6))).T)\n",
    "    R=covLoc(R,2)\n",
    "    np.save('R.npy',R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41c502e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/WithLabel\\140120_1.xlsx\n",
      "data/WithLabel\\140206_1.xlsx\n",
      "data/WithLabel\\140207_1.xlsx\n",
      "data/WithLabel\\140207_2.xlsx\n",
      "data/WithLabel\\140214_1.xlsx\n",
      "data/WithLabel\\140214_2.xlsx\n",
      "data/WithLabel\\140227_1.xlsx\n",
      "data/WithLabel\\140313_1.xlsx\n",
      "Timestamp in selected Test df list: \n",
      "140206_1.xlsx\n",
      "Origin input DF feature num(excl time, incl. label):  91\n",
      "Conc scaler max:  [12.03671837]\n",
      "Minimum call back is:  1\n",
      "The smallest feasible callback is:  1\n",
      "train list:  7\n",
      "Train df(1st one) shape before AE:  (117, 97)\n",
      "Test df(1st one) shape before AE:  (50, 97)\n",
      "LSTM x_train shape:  678\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 90)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5824      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 6,864\n",
      "Trainable params: 6,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 90)                5850      \n",
      "=================================================================\n",
      "Total params: 6,938\n",
      "Trainable params: 6,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 90)]              0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                6864      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 90)                6938      \n",
      "=================================================================\n",
      "Total params: 13,802\n",
      "Trainable params: 13,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "17/17 [==============================] - 2s 9ms/step - loss: 0.0777 - val_loss: 0.0615\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0376\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0248\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0212\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0196\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0160\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0124\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0069\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 136/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 298/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 460/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "INFO:tensorflow:Assets written to: DAE\\assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.00248018628611014\n",
      "Val:  0.0027794969290834996\n",
      "Test:  0.017266909197896516\n",
      "Train df(1st one) shape after AE:  (117, 23)\n",
      "Test df(1st one) shape after AE:  (50, 23)\n",
      "Number of set:  100\n",
      "Number of set:  101\n",
      "Number of set:  33\n",
      "Number of set:  50\n",
      "Number of set:  33\n",
      "Number of set:  201\n",
      "Number of set:  211\n",
      "Number of set:  33\n"
     ]
    }
   ],
   "source": [
    "reset_random_seeds()\n",
    "ReLu = tf.keras.initializers.HeUniform()\n",
    "data_path_list = glob.glob('data/WithLabel/1*.xlsx')\n",
    "\n",
    "list_of_origin_df=[]\n",
    "for i in range(len(data_path_list)):\n",
    "    xls = pd.ExcelFile(data_path_list[i])\n",
    "    data_df = pd.read_excel(xls, sheet_name=0, index_col=0, header = [0,1])\n",
    "    data_df.columns = data_df.columns.map(''.join)\n",
    "    data_df=data_df.rename_axis('time').reset_index()\n",
    "    tmp_name=list(data_df.columns)\n",
    "    tmp_name[-1]='label'\n",
    "    data_df.columns=tmp_name\n",
    "    list_of_origin_df.append(data_df)\n",
    "\n",
    "for string in data_path_list:\n",
    "    print(string)\n",
    "list_of_processed_df=list_of_origin_df.copy()\n",
    "test_df_index_list=[1] # Select the index of test dataset\n",
    "callback=17 # length of past records excl. current time step\n",
    "# getDataSet(path_list,df_list, callback, test_df_index_list, mode, reduced_dimension)\n",
    "# mode ={'PCA', 'DAE', 'POD'}, reduced_dimension = {'32', '16'}\n",
    "train_sample_set, train_label_set, test_sample_set, test_label_set, conc_scaler,train_df_list,test_df_list,test_conc_list \\\n",
    "=getDataSet(data_path_list,list_of_processed_df, callback,test_df_index_list, 'DAE', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f2e34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample_set shape:  (729, 18, 22)\n",
      "Train len: 583, Val len: 146\n",
      "x_train shape: (583, 18, 22), y_train shape:(583, 1, 6)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 18, 100)           49200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 18, 100)           10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 18, 100)           10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18, 6)             606       \n",
      "=================================================================\n",
      "Total params: 70,006\n",
      "Trainable params: 70,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "15/15 [==============================] - 3s 36ms/step - loss: 0.2636 - val_loss: 0.2556\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2529 - val_loss: 0.2450\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2431 - val_loss: 0.2346\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2330 - val_loss: 0.2245\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2229 - val_loss: 0.2147\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2133 - val_loss: 0.2052\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2037 - val_loss: 0.1959\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1951 - val_loss: 0.1868\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1863 - val_loss: 0.1779\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1772 - val_loss: 0.1692\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1687 - val_loss: 0.1607\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1609 - val_loss: 0.1524\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1529 - val_loss: 0.1443\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1446 - val_loss: 0.1365\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1369 - val_loss: 0.1288\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1300 - val_loss: 0.1214\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1227 - val_loss: 0.1142\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1156 - val_loss: 0.1073\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1088 - val_loss: 0.1006\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1021 - val_loss: 0.0943\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0964 - val_loss: 0.0882\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0905 - val_loss: 0.0824\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0848 - val_loss: 0.0770\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0797 - val_loss: 0.0719\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0745 - val_loss: 0.0671\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0699 - val_loss: 0.0626\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0656 - val_loss: 0.0584\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0615 - val_loss: 0.0545\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0581 - val_loss: 0.0509\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.0476\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0513 - val_loss: 0.0446\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0485 - val_loss: 0.0418\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0455 - val_loss: 0.0393\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0431 - val_loss: 0.0369\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0409 - val_loss: 0.0348\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0329\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.0311\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0295\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0280\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0321 - val_loss: 0.0267\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0254\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0295 - val_loss: 0.0243\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0233\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0223\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0262 - val_loss: 0.0215\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0207\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.0199\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.0192\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0186\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.0180\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0216 - val_loss: 0.0175\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.0169\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0207 - val_loss: 0.0165\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.0160\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0156\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0152\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0148\n",
      "Epoch 58/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0145\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0141\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0138\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0135\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0168 - val_loss: 0.0129\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0127\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0124\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0121\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0112\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0093\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0090\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0089\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0086\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0078\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0077\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0074\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0073\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 115/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0034\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 9.9903e-04\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.9807e-04\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.9493e-04\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.9394e-04\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.9481e-04\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.8058e-04\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.7795e-04\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 9.8059e-04\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.8098e-04\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.7021e-04\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.6936e-04\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.6913e-04\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 9.5796e-04\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 9.5663e-04\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 9.6001e-04\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 9.5823e-04\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.4653e-04\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.5140e-04\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.4873e-04\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.3723e-04\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.3342e-04\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.3989e-04\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 9.3263e-04\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 9.3740e-04\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 9.2821e-04\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 9.3133e-04\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 9.1992e-04\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 9.1628e-04\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 9.1369e-04\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 9.1787e-04\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 9.1903e-04\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 9.0573e-04\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 9.0562e-04\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 9.0800e-04\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 8.9617e-04\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 8.9418e-04\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 8.9499e-04\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 8.9444e-04\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 8.8621e-04\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.8882e-04\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 8.9429e-04\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.8371e-04\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.7859e-04\n",
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.9048e-04\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.7263e-04\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.7015e-04\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.7049e-04\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.6113e-04\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.6387e-04\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.6496e-04\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 8.6071e-04\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.5919e-04\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.5495e-04\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.5212e-04\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.5151e-04\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 8.4764e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.4557e-04\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.4854e-04\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.4807e-04\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 8.3684e-04\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.3814e-04\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.3587e-04\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 8.2624e-04\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 8.3368e-04\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.2711e-04\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.3284e-04\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.2314e-04\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 8.2047e-04\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 8.1560e-04\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.2263e-04\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.1357e-04\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.1384e-04\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.1045e-04\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 8.1108e-04\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.0902e-04\n",
      "Epoch 489/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.0301e-04\n",
      "Epoch 490/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 7.9878e-04\n",
      "Epoch 491/500\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 7.9654e-04\n",
      "Epoch 492/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.9813e-04\n",
      "Epoch 493/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 8.0058e-04\n",
      "Epoch 494/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.9601e-04\n",
      "Epoch 495/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.8958e-04\n",
      "Epoch 496/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 7.9008e-04\n",
      "Epoch 497/500\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 7.8651e-04\n",
      "Epoch 498/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 7.8520e-04\n",
      "Epoch 499/500\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 7.8610e-04\n",
      "Epoch 500/500\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 7.7961e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "MSE: 0.07168900442909397\n",
      "Evaluate on validation\n",
      "MSE: 0.06500564687033011\n",
      "MSE:  0.07168900442909397\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABEmUlEQVR4nO3dd3xcV5nw8d9zp2jUq5vcZDtxiXuJ0xwSSEhvpEGAEGpYWCB5WRY2tASWQEJbSthlQ4cEskASCCWQBOL02HHviXuVbRVLVteU5/3jXEkjS7IlW6P6fP2Zj2buueWZ65nnnjn33nNEVTHGGDP0ef0dgDHGmL5hCd8YY4YJS/jGGDNMWMI3xphhwhK+McYME5bwjTFmmLCEb4YVEblQRPadYJ6NInJh30SUet15z0nz3iMiD6U6JtM/LOGblBGRXSLSICI1IlIlIi+LyL+ISLc+dyJSIiIqIsFUx5pMVWeq6tK+3KYxfcESvkm1q1U1G5gI3Ad8BvhJ/4bUub4+sBjT1yzhmz6hqtWq+gTwduA2EZkFICJXishqETkqIntF5J6kxZ73/1aJSK2InCMiU0TknyJSISLlIvKwiOR1tV0RSReRn4vIERHZBJx5TPkuEfmMiKwD6kQk6E+7WESK/V8oBUnzz/e3G/Jfv19ENvvr/7uITEyaV/1fNFv98h+IiHQR5z0i8jsRecj/RbReRKaKyF0ictjfN5ckzV8sIk+ISKWIbBORD/XgPReLyKMiUiYiO0XkE13tPzO0WMI3fUpVlwP7gPP9SXXAe4A84ErgIyJynV/2Jv9vnqpmqeorgABfA4qBGcB44J7jbPJuYIr/uBS4rZN5bvG3naeqsaRYDwCvADckzftO4PeqGvXj/CxwPTACeAH4zTHrvgqXcOcCN/sxdOVq4FdAPrAa+DvuOzoW+DLwv0nz/ga3H4uBG4GvishFJ3rPfnPan4C1/novAu4UkePFZYYIS/imPxwACgBUdamqrlfVhKquwyWyC7paUFW3qerTqtqkqmXAt483Py7J3quqlaq6F/heJ/N8T1X3qmpDJ2W/xh0Q8Gvn7/CnAXwY+JqqbvYPFF8F5iXX8oH7VLVKVfcAzwLzjhPrC6r6d39dv8MdRO5T1SjwCFAiInkiMh5YAnxGVRtVdQ3wY+DWbrznM4ERqvplVW1W1R3Aj/z3ZYY4S/imP4wFKgFE5CwRedZvXqgG/gUo6mpBERkpIo+IyH4ROQo81DK/iLzLb/qpFZEn/UWKgb1Jq9jdyWr3djKtxe+Bc0SkGPeLQ3E1eXDnJb7rn5Cu8t+T+O+vxcGk5/VA1nG2dSjpeQNQrqrxpNf4yxcDlapakzT/7qTtHu89TwSKW2L24/4sMOo4cZkhwhK+6VMiciYuMb3oT/o18AQwXlVzgR/ikia45Hqsr/nT56hqDvDulvlV9WG/6SdLVS/35y/FNfu0mNDJOrvsMlZVq4CncLXmdwK/0bYuZvcCH1bVvKRHuqq+3PUe6BUHgAIRyU6aNgHY7z8/3nveC+w8JuZsVb0itSGbgcASvukTIpIjIlfhmiYeUtX1flE2rrbaKCKLcUm1RRmQACYnTcsGanEncscC/36CTf8WuEtE8kVkHPDxkwj/17jzDDfQ1pwD7uB0l4jM9N9jrojcdBLr7xG/meZl4GsiEhGROcAHgIf9WY73npcDR/0T1ekiEhCRWf6B2AxxlvBNqv1JRGpwNcvP4drc35dU/lHgy/48X8QlKwBUtR64F3jJb344G/gSsACoBv4CPHaC7X8J16SxE1dT/9VJvIcngNOBQ6q6Nim+x4H7gUf85qUNwOWdr6LX3QKU4Gr7jwN3q+rTflmX79lvIroady5hJ1COa//P7aO4TT8SGwDFGGOGB6vhG2PMMGEJ3xhjhglL+MYYM0xYwjfGmGFiQHcWVVRUpCUlJf0dhjHGDBorV64sV9URnZUN6IRfUlLCihUr+jsMY4wZNESks7vJAWvSMcaYYcMSvjHGDBOW8I0xZpiwhG+MMcOEJXxjjBkmLOEbY8wwYQnfGGOGiQF9Hb4xxgx0dVVH2L1uNc0NDUyav4jckQN38DBL+MYY0wPxWJT9Wzaza90qdq1dRdmuHe3KR0woYcqZZ3PaorMZOWkKbijkgWFA94e/aNEitTttjTH9SVWpOniAXWtdgt+7cT3Rpka8QIDiaTMombOAkrkLCKens33lcravWMb+LZtQTZBVUMiUhWdx2qKzGDdzDsFQKOXxishKVV3UaZklfGOMaa+pvp49G9eye+0qdq1bTfUhNxZ97qjRrQl+/Mw5pGVkdLp8/dFqdq5ewbbXXmXXulXEmpoIp6czad4i3vK+D5ORm5ey2I+X8K1Jxxgz7GkiwaGd21tr8aVbt5CIxwmlRRg/aw4Lr7yOkrkLyB9d3K31ZeTkMvOCi5h5wUVEm5vYu2Ed21a8yoZnnyZ35CjOf+d7U/uGumAJ3xgzLNUeqWT3utXsWruK3etW01BzFICRJVNYdNXbKJm7gOJpMwgET60ZJhROY/KCM5m84EyqDpayfeVyS/jGGJNKsWiU/Vs2ugS/dhVle3YBkJGbR8m8hZTMXcDE2fPIzMtPWQxTFi5m6S9/TPXhg+SOHJ2y7XTFEr4xZkhSVY6U7m872bppPbGmJrxAkLHTZrDkltsombuAkRMnIV7f3JI02U/421cuZ8Hl1/TJNpNZwjfGDBlN9XXsWb/WJfl1qzhadhiA/DHFzLrwrf7J1tmEI+n9El/+6GIKisdZwjfGmJ5KJOIc2r6t7WTrttfRRIJwejoTZs1l8bU3UjJ3Qb80n3Rl8sLFrPrrEzTV13d5lU+qWMI3xgwqNZXlfoJfzZ71a2isrQERRk06jcXX3kTJ3PmMOX06geDATG9TFi5mxZ8eY9faVUw7Z0mfbntg7hFjjPHFmpvZt3lDay2+Yt8eADLz8pmycDET/ZOtGTm5/Rxp9xRPnUEkK5sdK5dZwjfGDG+qSuX+fa3t8Ps2bSDW3EQgGGTs9JnMvOAiSuYuoGhCyYDqtqC7vECASfMXsWPNShKJOJ4X6LNtD8mE/7P/9y8E09LILiwiq6CI7IJCsotGkF1QSFZhEVkFhYTCaf0dpjHG11hby54Na1qbamoqygDILx7H7IsucSdbZ8wmFIkcf0WxJmishqYa9zp7DIQzIB6FWCN4IQiEoY+uyunKlIWL2fzCsxx4Ywvjps/ss+0OuYSviQTjZsyipqKM6sOH2L95I411tR3mi2TnuAOBfwDILhyR9LyI7IKiE3+4jDEnJZGIc3Db1tZa/MGtb6CaIJyewcRZcznn2muZeNoEcoonQXo+1B6GNT+H+gpoOOKSemMVnHcHlCyBnc/Dwze5pJ7snb+FqZfCG3+H/3tX23TxXOJ/1+9h0vmw4zlY9kNIL4CMAsgodI/pV7rX9ZVuu6EMCKVDOBMCJ39DVsncBXiBADtWLreEfyrE83jr7R9rNy3a2EhNZQW1leXUVLhH6/PKCkq3vt56l12ytMxMsguKyCosaj0IZBUWkl1Q1Prroa/PshvTKxIJiDWAKqRluWmHN0NzHUQbXE05Wg/Zo2H8Yle+9D5Xc26udfM118PkC+CsD0MiDr+81q0Pv38uVZh9I5z5AWiqIf6zq2mqq6Wpvo7m+jq8RJzaqjFo0ZtYcvWlzD/8Y4KJRqThOXilEV4BrvgmLP4Q1JXB3z4DCERyIT0PInkuVoDc8W6+SK6bnpbj4hg925WPnAGX3AvxZkjE3N94MxRMcuXNtVC1Fw6scQeVeJObPv4sl/DX/gb+/tn2+9ALwh3rIHcsLP8RrPiZOxiE0tsODNf9tzs4vPEU7FsOwQh4AdIQ3jKtmVUrl/Omd70Ptv8TDm0CEfce577DbbeXDbmE35lQJEJB8VgKisd2OU+0uYm6ykpqOjko1FZWcHjnduqrqzosF07PaPfLIKugiOxC/xeD34SUlpE5KNsaTT9LxF3NMmuEe735T3Bkl0tyLYk5ayS86VOu/E93QtkW13wRb3Z/x8yB6x905Q9eCOVb25IdwNTL4Z2PuOe/uAbqDrePYdYNbQn/5QdAEy6BhTMhnNW+Rq0J/4mACAlNULlvLxs2/4h9a5dzvuxEgUAoTCR7BOk5eVx4w22EF78H6irgTy+7ZJ1cwx5/lltl0TT49E6X0Dtr8y6YBJd8pet9WTgFzv1Y1+XTr3QPcAeq5jqX+HP8vnNOe6uLJ1rv9nu03h3wIv6J4owCF0O0wT1qD7m/4se663m3/2jrrHIOwjP7A1QdLCVvw2Ow+ldt8Zx2cUoSvvWW2QOxaJS6IxWtvwxqK8rdAaLcPzAcqaCu6ohfy2kTSou0+5WQXVjoHxj8A0XRCCKZWXZQGI4aq9uSxoZHXdNC1W44shuq97na4x1rXfkvroGdz7nngbCrRY6ZC7c94aY98Qmo3OHKAmEIhmHEDHjzXa78uW+4ZolAyNU0QxEoPB1mXOXK33gKUL/Mr6lmFEHOGFeeSBy37VtVqdi3p/Vqmv2bNxKLNhMIhRg3YxYlc+ZTMncBheMnDs/Puqr/CyMOKFWHD/KTf7uDC9/zIRZecokra/mFlJbT+YGtG6x75D4Uj8Woq6qkpqKCmooy/6DgHxz8A0TdkSNoa23ICYbT2g4E/i8Dd16h7eCQnp0zPL8oQ8X+lbBjKZRvg4ptULHV1RI/V+q+3E98HLb8BfJLIG8i5E+Egimw4Fa3fEOVmy+YDoGB8eO8obaGPev9k63rVlNbUQ5AwdjxlMx13QiPmzGTUJqdD+vMz//to2Tm5XHTF77aa+u07pH7UCAYJKdoJDlFI4EZnc6TiMepqzqS1GzkDg4tB4a9mzZQe6QCTbQ/KARCoXbnEbIK2w4OOYUjyCooJCMnt8/6BTHHqNoLe16F6j1QtcfV0iu3wwf/6Zpltv0Dnr3XXTlSeBqccZ37G4+6RH7Vd+Ca73e9/vS8PnojXUvE45Rue6O1A7KD27eimiAtM5OJs+Yx8YZbKJk73//8mxOZvHAxK//8OE31daRlZKZ8e32a8EXk/wEfxDVkrQfep6qNx19q6PECAde8U1jU5TyJRJz66uq2ZqOK9ied97++mbojFcRjsWPWHfTPJ7jzCMlXHbUcKDLy8vr02t8ho+agO7lWtaftUb0Xbvo5FM93V4r88aNu3oxCyJsA4xa3nQBcfDuc/RFIy+58/QP0/+Ro+eHWZpo9G9bSVFeHiMfo007n7BveTsncBYyeMhUvMDDjH8imLFjMa3/8PTvXrGT6uW9K+fb6LOGLyFjgE8AZqtogIr8F3gH8vK9iGEw8L0BWfgFZ+QWMZmqn82giQUPN0dZzCsc2IR3c/gY1y8uJR6PtlhPPIyu/MOmKo5Zmo7YmpKz8guHxBVZ1baqBoGsy2fq0a0Ov2t1WS7/0qzD9CndC9A8fcctljXYJfewi114OMO1y+NflkDvOndQ81gCooXdHtKmRfZva7mytPLAPgKzCIk5ffB4lcxcwYfZc0rO6OHCZbhszdRrp2TnsWLl8aCX8pO2li0gUyAAO9PH2hxTxPDJy88jIzWPU5NM6nUdVaag5Sm1lRYcmpNrKcsp272THqteINTe1X7d4ZObluV8JXTQhZebnn/LgECnTXOeulKgtg8wid5VGQxU8c4+7prv2UNvfi++Gc/7VXfr32Afd8pkjXDt68fy2RD3uTPj4KpfQg53cuJdRkJIrK1JNVSnfu7vtZOuWjcSjUYKhMOPOmMWciy+jZO4CCsaOt3NIvczz/LtuVy4nEY+nvJLVZwlfVfeLyDeBPUAD8JSqPnXsfCJyO3A7wIQJE/oqvCFLRMjIySUjJ5eRJZM7nUdVaaqr85uOyqitqGi9PLW2soKKvXvYtWYV0abGY1dOZm5eu0tR2zchuauQenXg5tK1LjHXV7rL5uorYOQZMOt6iMfggUUukUfr2pY552Nw6b3u6pTNT7jaefYoKDrdXdZYPN/NlzcRProM8sZ3XkMPZ7oDxxDQUHPUH+1pNbvXraL2SCUAheMmMO+SKyiZs4CxZ8yyO9L7wJSFi9n0/D858Ppmxp0xK6Xb6ssmnXzgWmASUAX8TkTeraoPJc+nqg8CD4K7Sqev4hvORIRIVhaRrCxGTCjpdB5Vpam+jtrWy1H9E83+uYUjpQfYu3E9TfV1HZbNyM1ru08hv5D83DTy0+NkpwvpaRApGEPwDP/SwKe/CBXb3eWKDVXQUAkTzoEbf+LKf3U91JcnBe/BvHe5hB8Iursu03JcIs8aCZkjocj/9RPOhE/v6HpHBMMwcnrPd+AgkIjHObB1ixuUe+0qDu7YBqpEMrOYMGc+JXPnUzJnwXHPK5nUmDhnAV4gyPZVy4dOwgcuBnaqahmAiDwGnAs8dNylzIAgIkQys4hkZlE0fmKX8zU31FNTXkb9/i3ESjeRKN9Oc20VmxvzqD58iMUVP6E4cqTdMgcasnm84k1kFxRyadZzZHoNJNLc3ZRe/mwkbwbhxkbX1cWNP3HXibfcmHPsjTjXPpCqXTDoVB8+1O5ka3NDPSIeY06fxrk3vpOSuQsYNeU0O4Hfz9IyMhg/czbbVy7ngne/P6Xb6suEvwc4W0QycE06FwGD6yJ707nmutYmkPA/Pkfhml9TmHwHZtZoZtzlH9dXnUW87gj1gTzqmj1q62NU18aYdrSZmooy/l55IbUV5UldXdQBS+FHS11XF0l3MLdceVQwZhzF02YM+/blaGMjezetb03yR0r3A5BdNIJp557vTrbOmkskM6ufIzXHmrxgMc/+/H85Urqf/DFd9whwqvqyDX+ZiPweWAXEgNX4TTdmkGmsht2vwK4XYNeLcHgT/Pt2iOTA+LNd8s+fBAWT3e3mOePall1wKwEg2390JdbcTE1l+TFNSG1dXhw6pquL825+N2ff8I4UveGBSVUp273TXRO/bhX7t2wiHosRDKcx/oxZzLvkCibOXUBB8bhhfzAc6KYsdAl/+8rlLLrqbSnbTp9epaOqdwN39+U2TS+or3RXpYQzYd1v4fEPu35TAmF3nfn5/+Y6pAKY+3bg7ae8yWA4TP7oYvJHF3c5TzwWpbaykpd/+xAv/fYhItk5zLvkilPe9kBWf7S6tR1+17rVrQe9ogklzL/8GneydfoZBMPh/g3U9EjuyFEUjZ/IjqGU8M0gUbXH1eD3+I+yLXDjT11HWsUL4E2fdidHxy1y/a30k0AwRO7IUVzyL3fQWF/HP376P0QyM5l+3gX9FlNvi8diHHhjc2szzeGd2wHXvffE2fNc9wVz5pNVUNjPkZpTNXnhYl574lEaa2uJZKWm2c0S/nAXa3IJPRB2XchW7YHv+F3KpuW43grn3Ayj57ppRae1dcY1QASCQa668zM89tW7efIH3yYtM4tJ8xb2d1gnrerQwXYnW6ONDYjnUTx1Oufd/G5K5i5g5OQpdrJ1iJmycDHL//A7dq5dyYwUVVos4Q9HL3/f9ft9aCOUvwEah9k3wQ0/dv2KX/1dGLvQXd8+SJJKKJzGdZ/+Ar/90md54ltf5cbPf4Wx0zrvy2igaW5sYO/Gda1JvupgKQA5I0YxY8kFrSdb+6KvFdN/Rp82lYzcPHasXG4J3/TAwfWuN8ajB1yN/dBGdwfozb905Wt+DU21MGqm6wN81EyX4MENwLDwvf0W+qlIy8jkhs9+iUfu/jSP338Pb7/n/i7vK+hPmkhwuOVk69pV7H99M4l4jGBaGhNmzmH+ZddQMncB+WOK7WTrMNJy1+22114hHosRCPZ+eraEfypU3cnLRNzVkgNprr/wphrX73g82nEwikDI73Rrf9t6Wr7U4850NerKHa7nxViTG2CiZfl5t7j5Xn8SDqyGunKoKXWJXQRuX+rKn/kSbHvaPQ9luJp6XtK187cv7bxrgCEgIzePGz/3FX7zxX/n0Xu/wDu+/A3yRo3u77Cor65i17rV/hU1bSdbR0woYcEV1zBp3kKKp53Ru3clm0FnysLFbFz6DAde38T4mXN6ff3DI+En4u4W/HCWG9C4Yjts+qOb1lznj2JTD2/5AoyYBlv+6u74bJkej7rE/oGn3JBpr/0Y/vJvHbfzidXuUsTXfuz6bDnWp7a6uz9X/RKe/0bH8s+WuviW/a8bXzOZeG7YMxHY8mdY/ZAb6zO72A1QkZzQ3/pluPgeN1pPen7bAaXFEE32LXJGjOTGz/0nj9z9GX5/7+d5x5e+TlZ+3/ZxE49FOfD65tZBuQ/vcidb07NzmOgPBDJxzvw+j8sMbBPnzCcQDLJ95XJL+N12eAs89fm2DrLqylwN/B2/dk0YlTvhH19yA0mEM12SDWW6Zg5wSXL0LDctlO5OaIq4OzsBxsx3V6p4AZeIRdxQZpE8V37aW13nW4GwG/eyZQSitBxXPu+dMPE8P9ik3iNaEvGZH4IZV7s7SoNp7m8g6TK7q74LV3+/69GHRp3RG3txUCscN4Hr77qH3335czz61S/y9rvvS9mVDy2OHDzArjUr2bV2FXs3rifa1IgXCFA8dQZL3vEed7K1ZLKNV2C6FI6kM37WXHasWs6F7/lgr69/aI54VfaG6/Uwa1TbI3u0GyeyYBLEmiER7byDLDOk7F63hsfvv4dRk0/nxs/9p+ueoZc01dezZ+Nad138utVUHzoIQO6o0ZTMcaM9jZ85xwa6Nz2y9bVXqNy/jzOvvv6kes+0IQ7NsPbGspf483/dT86IEUw9ewmnn3Uuoyef3uOatiYSHNq5vfVqmtKtW0jE44TSIoyfNad1SL/j3SxmTKpZwjfD3vaVy1j9tz+zd+M6EvG4G8zjzHM4ffE5jJ0+s8uaVO2RSr8bYXeytaWPn5ElU1wPk3MXUDxtxsAdF8AMO5bwjfE11tayY9Vyti5/mV1rVhGLNpOencOURWdz+lnnMG76TA5u38rONSvZvXYVZXt2Ae7qn9aTrbPnkZmX379vxJguWMI3phPRxkZ2rl3J1mUvs2PVcpobGlrLvECQsdNmMNFvphk5cZKdbDWDwvES/tC8SseYbghFIkw96zymnnUesWiUvRvWcmDrFkZPOZ3xZ8wmnG4nW83QYgnfGCAYCjFp/iImze+0YmTMkGC/UY0xZpiwhG+MMcOEJXxjjBkmLOEbY8wwYQnfGGOGCUv4xhgzTFjCN8aYYcISvjHGDBM9Tvgikikig2OgU2OMMa1OmPBFxBORd4rIX0TkMLAFKBWRjSLyDRE5PfVhGmOMOVXdqeE/C0wB7gJGq+p4VR0JnA+8CtwnIu9OYYzGGGN6QXf60rlYVaPHTlTVSuBR4FERsc7AjTFmgDthDb+zZH8y8xhjjOlfJ3PS9mwR+aeIvCQi16UgJmOMMSlwwiYdERmtqgeTJn0SuAYQ4GXgD6kJzRhjTG/qThv+D0VkJfANVW0EqoB3AgngaApjM8YY04u604Z/HbAG+LOI3ArciUv2GcB1qQvNGGNMb+pWG76q/gm4FMgDHgNeV9XvqWpZCmMzxhjTi7pz49U1IvIi8E9gA/AO4G0i8hsRmZLqAI0xxvSO7rThfwU4B0gH/qqqi4FP+nfY3os7ABhjjBngupPwq3FJPR043DJRVbdiyd4YYwaN7rThvw13gjaGuzrnpIlInoj8XkS2iMhmETnnVNZnjDGm+7pTw69Q1e8fbwYREVXVbqzru8DfVPVGEQnjDiTGGGP6QLc6TxORj4vIhOSJIhIWkbeIyC+A2060EhHJAd4E/ARAVZtVteokYjbGGHMSupPwLwPiwG9E5ICIbBKRncBW4Bbgv1T1591Yz2SgDPiZiKwWkR+LSOaxM4nI7SKyQkRWlJXZVZ/GGNNbpHstMf7MrlfMIqChp7VzEVmE6075PFVdJiLfBY6q6he6WmbRokW6YsWKnmzGGGOGNRFZqaqLOivrTht+y0rSgBuAEiAoIgCo6pe7uYp9wD5VXea//j3wH93dvjHGmFPTk94y/whci7tapy7p0S1+B2x7RWSaP+kiYFMPtm+MMeYUdLuGD4xT1ctOcXsfBx72r9DZAbzvFNdnjDGmm3qS8F8Wkdmquv5kN6aqa4BO25aMMcakVk8S/hLgvf4VOk24/vBVVeekJDJjjDG9qicJ//KURWGMMSblun3SVlV347pHvtp/5PnTjDHGDALdTvgicgfwMDDSfzwkIh9PVWDGGGN6V0+adD4AnKWqdQAicj/wCnDcfnaMMcYMDD25Dl9wXSy0iPvTjDHGDAI9qeH/DFgmIo/7r6/D7wjNGGPMwNfthK+q3xaR54DzcDX796nq6pRFZowxplf1pIaPqq4EVqYoFmOMMSl0woQvIi+q6hIRqQGSu9ZsufEqJ2XRGWOM6TUnTPiqusT/m536cIwxxqRKT67Dv78704wxxgxMPbks862dTLPuFowxZpDoThv+R4CPApNFZF1SUTbwUqoCM8YY07u6c5XOr4Enga/RfoSqGlWtTElUxhhjel13TtpWA9W4AcuNMcYMUidswxeRF/2/NSJy1H/UtLxOfYjGGGN6g12WaYwxw0RPLsu8SUSy/eefF5HHRGR+6kIzxhjTm3pyWeYXVLVGRJYAlwK/AH6YmrCMMcb0tp4k/Jauka8E/kdV/wiEez8kY4wxqdCThL9fRP4XuBn4q4ik9XB5Y4wx/agnCftm4O/AZapaBRQA/56KoIwxxvS+ngxiXg9sBy4VkY8BI1X1qZRFZowxplfZIObGGDNM2CDmxhgzTNgg5sYYM0yc7CDmAlyLDWJujDGDRk8HMV8KLPEn2SDmxhgziHQ74YtIBLgQOB9IAAER2ayqjSmKzRhjTC/qSZPOL4Ea4Hv+61uAXwE39XZQxhhjel9PEv40VZ2b9PpZEVnb2wEZY4xJjZ5cpbNaRM5ueSEiZ2FDHBpjzKDRkxr+WcB7RGSP/3oCsFlE1gOqqnN6PTpjjDG9picJ/7KURWGMMSblenJZ5u7e2KCIBIAVwH5Vvao31mmMMebEenJZ5iLgc8BEfznh5Jpy7gA2Azk9XM4YY8wp6EmTzsO47pDX467D7zERGYcbQOVe4JMnsw5jjDEnpycJv0xVnzjF7X0H+DTQ5YDoInI7cDvAhAkTTnFzxhhjWvQk4d8tIj8G/gE0tUxU1ce6s7CIXAUcVtWVInJhV/Op6oPAgwCLFi3SHsRnjDHmOHqS8N8HTAdCtDXpKNCthA+cB1wjIlcAESBHRB5S1Xf3IAZjjDEnqScJf66qzj7ZDanqXcBdAH4N/1OW7I0xpu/05E7bV0XkjJRFYowxJqV6UsNfAtwmIjtxbfgne1kmqroUWNrT5Ywxxpw8u9PWGGOGiW436fh32uYBV/uPvN66+9YYY0zqdTvhi8gduJuvRvqPh0Tk46kKzBhjTO/qSZPOB4CzVLUOQETuB14Bvp+KwIwxxvSunlylI0A86XXcn2aMMWYQ6EkN/2fAMhF53H99HfCTXo/IGGNMSvSke+Rvi8hS3OWZArxPVVenKjBjjDG9qyc1fFR1FbAqRbEYY4xJoZ5cpfMLEclLep0vIj9NSVTGGGN6XU9O2s5R1aqWF6p6BJjf6xEZY4xJiZ4kfE9E8lteiEgBPWwSMsYY0396krC/BbwsIr/HdYt8M27kKmOMMYNAT67S+aWIrADegrtK53pV3ZSyyIwxxvSqnl6lswmwJG+MMYNQT9rwjTHGDGKW8I0xZpiwhG+MMcNEjxO+iLxVRH4kIvP817f3elTGGGN63clcR/9R4H3A5/1r8ef1akTGGGNS4mSadMpUtUpVPwVcApzZyzEZY4xJgZNJ+H9peaKq/wH8svfCMcYYkyo96TwtIiKzgG0iEmmZrqo24pUxxgwCJ0z4IhIUka8D+4BfAA8Be0Xk6yISSnWAxhhjekd3avjfAAqASaq6UFXnA1OAPOCbKYzNGGNML+pOwr8K+JCq1rRMUNWjwEeAK1IVmDHGmN7VnYSvqqqdTIzjes00xhgzCHQn4W8SkfccO1FEbgW29H5IxhhjUqE7N179K/CYiLwfWImr1Z8JpANvS2FsxhhjelF3En468G9AGJiJ6wv/SSAKRI6znDHGmAGkOwn/O8BnVXUd8M+WiSKyyC+7OiWRGWOM6VXdacMv8ZN9O6q6Aijp9YiMMcakRHcS/vGabdJ7KxBjjDGp1Z2E/5qIfOjYiSLyAdxJXGOMMYNAd9rw7wQeF5F30ZbgF+FO4tpVOsYYM0icMOGr6iHgXBF5MzDLn/wXVf3ncRYzxhgzwHR7ABRVfRZ49mQ3JCLjcV0pjwYSwIOq+t2TXZ8xxpieOZkRr05WDPg3VV0lItnAShF5WlU39WEMxhgzbPXZIOaqWqqqq/znNcBmYGxfbd8YY4a7Pkv4yUSkBJgPLOuk7HYRWSEiK8rKyvo8NmOMGar6POGLSBbwKHCn381yO6r6oKouUtVFI0aM6OvwjDFmyOrThO+PkPUo8LCqPtaX2zbGmOGuzxK+iAjwE2Czqn67r7ZrjDHG6csa/nnArcBbRGSN/7ARs4wxpo/02WWZqvoirmtlY4wx/aBfrtIxxhjT9yzhG2PMMGEJ3xhjhglL+MYYM0xYwjfGmGHCEr4xxgwTlvCNMWaYsIRvjDHDhCV8Y4wZJizhG2PMMGEJ3xhjhokhmfA1of0dgjHGDDh9OaZtn/nZZ14kGAqQXRghuyDS8W9BhEBoSB7rjDGmS0Mu4WtCOWNJMTWVjdRUNLJ/6xHqljehx1T6M3LCXR8QCiOEI0Nu1xhjhrkhl9XEE86+dkq7afF4grojTe4g4B8Iairc87I9NexYW0Yi1v6IkJYR7PKAkFOYTlpmEDemizHGDA5DLuF3JhDwyClKJ6covdNyTSj1R5vbDgb+36MVjVQdbmDvliPEmuLtlgmmBVqbh7ILI+Qcc1DIyAkjnh0QTEeqSlMs4R7ROE2xBCOy04iEAhypa2ZPZT3ReIJoXIklEsTiyqKSfLIjIQ5WN7KzvI5wUAh6HqGARzgoTCjIJBz0qGmMUlUfJaFKLKEkEkpcldNGZBEMeByoaqC0uhER8ETw/L9njMnB84TDNY1U10cREUTaBrCYPCILgLKaJuqaYgC01HcEYUJhBgCl1Q3UNMZIqKIKCVWCnse00dkAvHGohiN1zcRVSSQgrkp6KMDiSQUAvLK9giP1zSRUiSfcOnIzQrx52kgA/rahlMq6KPFEgnjCvcfivHSumD0GgJ++uJOqerf+gAgBz+O0kVlcOceV/99re2iOKyFPCHiCJy72M0vc9h9duY+4fw4wGo1zaOdRdHcdY+MB4qq8GG0ggRIDEkAcZbIXYnowjSZV/tRci6IkAFVQYHYwjVnBNGo1wWNNNai/rOLe39mhdGYG06hIxPm/pqMo8L6CfN7/qcW9/tkbFgn/RMQTMvPSyMxLY/Tk3A7lqkpTXSzpQNDQ7uBwaFc1TXWxdst4QSE7/5hfB0nnELLy0/ACdh4h1aLxBA3ROEFPyAgHicYT7Cqva0umCSUWV8blp1Ocl05dU4wXtpYT8xNKNK7E4gkWleRz2shsDtc08tiq/TTHEjRG4zRGEzTG4rx90Xjmjs9jw/5qvvbkZjfdT+ZNsTj3Xz+Hc08r4qmNB7n9Vys7xPnbD5/D4kkFPPv6YT7527Udyv/88SXMGpvL05sO8oU/buxQvvRTF1JSlMlDr+7h/r9t6VC+4vMXU5SVxq+X7eGBZ7d1KN/yn5cR8QL8z9Lt/OylXe3KPIEdX7sSgG/8fQu/XbGvXXl2JMj6ey4F4Ct/3sxf1pe2Kx+TG+GVuy4C4N6/bOa5N8ralZ82MotnPnkBAN966nVW7D7Srnzu+LzWhP+dZ7ay5WBNu/JzpxS2JvyfvbyTvZUNBDxpTdyXzhzVmvDv/9vrVNY1t1v++vljWxP+XY+vpzmWaFd+dijCjOIRxFV5ck95234BAiJk5oRYnBehPpFg24EjeLgDpSeCADMyA+RkR9BYnKrDR/H8ferhDqrh7BA5mRGisRgZFQEEISsvQiqIHtu4PYAsWrRIV6xY0d9hdEtzY6xDc1Hy6/qj7T9kIpCZn9ahqajldVZBGsFQIGXxJtcym2MJFGVktvuQ7a2sp7YpRiwpKaYFPeaMywPg5e3llNc2E40l/JpogsKstNYv3UOv7qaqvhkRaa1FTijI4HK//Hcr9lLXFCOuEE+4muyUEZlcNsuVf/vpN1x5oq2Gu3BiPjctGg/ARx5aSTTelqyj8QSXzxrNe8+bRF1TjAu/uZTG5jgN0Tgx/0t/58Wnc+fFUzl8tJHFX/1Hh/3x2Sumc/ubprCzvI43f3Nph/KvXDeLd589kQ37q7nq+y8CEPSESChAJOTxletmcdmsMWzYX83dT2wkEvJIC7qySDDA+5dMYtbYXLYdruWJtQdIC3pEQgHSgh7hgMeF00cwMjtCaXUDm0uPEvQ8ggEhFPAIesK00dlkhIMcOtrI9rLa1vfd8kvgLdNHkpkWZHPpUdbvryYgQjDg9n/AE94yfSSRUIAdZbXsqaz3PwOuBp5QeMv0kQQ8YcP+anaW15E4Ji9cO28sACt3H2FPZV3rOTFVCAc9rp5b7JdXUlrd2Pr/LuL20QVTRwCwYX811Q3R1rgCHqSHgpxRnAPA7oo6GqOJ1mUDnpAW9CjOc7/OD9c0kkjgL+se4YBHeth9VxIJxUv6ZR1PKAlVQn7l6khdM9GWXwdxV5aZFqQgI8zu9eU894/dHNhaRSAgTJxdxIxzxjDxtDzyMsKoKvXN8db/E2+A/oIXkZWquqjTMkv43dOyn0SEhuY4FXVNNLf8LPeT5qyxOWSEg5RWN7CzrA6l5WedEoslmJ6dQawmyubdVbxeepS6mih1Nc3U1zbTUB9jWpNHEOFAIMHBQIJAJEAoI0gwPUgoPcC7Z48lrzCd147UsKGylhjQHEvQHE+gCt+7ZT4AD/xzK89sPtxa1hxLkJkW5Mk7zgdcwnxyw8F2729cfjovfuYtALzrx6/y0raKduXTR2fztzvfBMB1P3iJNXur2pUvnJjPox85F4CLv/0c2w7Xtiu/YOoIfvF+9xP13K/9gwPVje3Kr5g9mv9+10IAFt/7DHVNMQKeS3gBT7h2XjGfu/IMAC7/7gsIEAwIQU8IBjyunD2G284tIRZP8IU/biASCpDe8ggHWDAxnwUT8mmMxnl60yFCAdckEggIIc9j0ohMxual0xSLs+1wbet2Q37izcsIkREOEk8oTbE44YBH0H6hDXqNtVE2vXSADc/tp6aykcy8NGa9aSxnLCkmIyfc3+GdlGGX8A8fbeSPaw7QHHfJOOonvesXjGVmcS6bS4/ywD+3tf7cbkmMn7/yDBZOzGfp64f57GPrW5dvSeyPfuQcFk4s4Hcr9vLvv1/XYbtP3nE+M8bk8IuXd3H3Ex1/dr/w6TczviCD/166ja//7fUO5Uv/dQnhxgTfe2E7j7xxqEP5nVURQghLI1HWpsUI4hJeOCBEggEeWDKN7IIIf9hTzqrDR4mktdUgc9NDfOnaWQD8cc1+dpTVkRZyZWlBj5z0UGstbtkO144a8JNd0BOyIyHmjc8DYFd5HbFEglCgpQ3ZrSM7EgLaalXJ7biCtNbCquqbSairpQX9WlpLgjWmtzU3xqitbKLmSCO1lY3U+hdw1FY2cnDHUeKxBGOn5jH7wnFMmls06Jtaj5fwh2Qbfml1I/f+dXPr61DA/exbODGfmcW5NETjbDl4lHAw4JJVwCMzHKQl3xRlpXHuaUWE/WSZFnLztDR5LCop4Os3zHHTg+6nezAgjC9wJ64unTmaaaOzEWh38mtEdhoANy0czwVTR7QmvJaft+PyMwh4whcmzOMzsQSBlhqs5xEAGuui1FQ0ckkXTUcv/d61zUaAc4Fg2Es6fxBi5d92kV0YYXFBFheXFHV5YvmsyYXH3b8lRZnHLQ94QuA449XnZQzOmpPpfYl4glg0QTyWIB71n/uvW59Hu5on3m6eeCxBzJ8n2pSgrrqJ2spGmurbn18Tgcw815x6xnljmPmmsRSOzeqnPdC3hmQNP+afqAsHPUKeN2Db2nqTqtJUH2t3ldGxB4TGumi7ZbygkJXfyZVG/uvM/DQCg7y2Y7qm6l/FEz1Bso21PI+3Jt5YNEGiy/mOeX6cdZ7qXfEiEAh5BEIewaDnPw8QDHlk5qWR5Z8nyypIIzs/QlZBhMzc8KCvxR/PsKvhBwMe2UP4P7QzIkIkM0QkM8SICdmdzpN8YrnWPxAc9Q8MezZWUF/dyYnlvLTj3rEcDKfuxPJQp6okYtqWHI9Tg+1WLbhDko0Tj2rSfPEO851qfU88Iegn3ICfcIP+85bp4Yxgu9dtibll3oC/vBAMB9rNm7y+zp4P5cSdCkMy4ZvOhSNBCouzKCzu/OdrPJqg5kj7exFa/pZuq2brisMdamTp2SGyk64uyi6IkDcynYLiTDLz0gb0zWnHJtyYnxC715zQWbKNdz7/cZY9VV5A2idAP1m2JtewRyQz2L4WHPQIhAMdE+kxibrzxBtIKhdLuIOMJXzTKhDyyBuZQd7IjE7LE/EEddXNfnNR+3sRKvbXsmtdOfGka5jDkQD5YzIpKM6kYIz/6OJAoKrEmhM0N8aINsaJNsVpbowdJ/F2kZy72ZTQsuyp8gJy3FpoOBIgEAp3TJ5Jtdx2td8O0wJ+IheCoUC7dQSCw6O50vQeS/im27yA19qUw+l5Hco1odTXNFN1qJ7KA3UcKa2jsrSOXevK2fxS28044UiAnBHpxKMJmhvjRBtjRJviJ9W8EAi6mmYgHOikqcAjLT1IRk5XtdWW54HWBBoICcGWJobOEnnSa0u4ZrCxhG96jXhCZm4amblpjJ2a366soaaZytI6Kg+4g0BNRSPBsEcoEiScFiAUCRCOBAmlBQhHAoQiQUKRAKFwoOvEG/Cs+wpjesASvukT6dlhxmaHOxwIjDF9x864GGPMMGEJ3xhjhglL+MYYM0xYwjfGmGHCEr4xxgwTdpWOMT2gqsQUEijxlv7kgTRPSPM8mhMJKqNxN2ITrjyuMDIcJCsYoDYWZ1dDE3HcaE8Jfx1TMyPkhYKUN8fYUtfgpuOXAwtzMsgPBSltamZTbaMbZKNlEA1gfk4GWcEABxqb2VbfRFTdSFcxP96LCrLJDAbYWNvA6qP1rmM/fx0CXDsyn/SAx8baBl6va2wtx5/nyqI8gp6wsbaBXQ1Nbcv7g3hcWuQGDlpztJ49jc2t/ekrEBTh6pF5ALx8pJa9jc24ERhc9+EZAY+3jXJXbz1VXs3+piiqfjmQFwxw42g3QMkfDh3hQFM06b0po9NC3FpcBMADuw9xoClKTLW188LTMtL44DjXH/93dh2kKhZvHXxEgKmZEW7213/fjlJq43ES/mhVCVUW5GTy9jGu/JNb9tDkjyIW9/+PLizI5tbiImIJ5db1O1pHulL//+9to/J5V3EhNbE4t67b4a+37f/3PWMLuWVMIYeaorxz3XZU4WezJzExPa03P7rAEE345XVNPLunosP0s0bnMiE/k4M1DTy/r6r1A5VQRVEuGFvAuNx0dh+p49n9Va1DkLV8uK4pGcHY3HTWH6zmL/sq3Zcq4coSwEenj2VcXjqvHajiqQNH8MTvOdLvDfO200eTnx5mRWk1L5UfbfehBvjw9GIyw0Ge31fJqxU1fly0Dpf26dkTCAc9ntxZxrIjtS5h4OJD4b4z3Vi+D205wCtVdcT9D5QqRDzh+2efDsD31+1leU1d6wdPUQqCQX7gl39zzW421De2jtrjCYwJhfjywkkA3LdmN9samvzYXIyT0sLcvcCVf27lDvY0+R21+VnjjPQId82bCMCnVmzncCzW+sVIAAuy0vnU7AkAfODVN6iKtwwC5+Y5PyeTT/rlN728haakfafAZXnZfHzmOJpjcS56ebP7QoJLCsC78rL59LxJHGlo5uxXN7cOQ4e//Y/m5/KpeZPYU13PuaveaFu3ggp8tiCXT8ydxMbD1Vy8aVeHz9a9RXl8YHYJK/ZVcP32/R3Kvz0in3fOmsgLOw7yvv1lHcp/ODKX62ZO4pktu7izorZD+a+K83jrtBL+tH47X6xp6lD+h0mjOLtkDI+s3crX66Mdyp+ZOoZZY0fxyIp1/Eg7JpLzwh7jC/P56YoNPKyhDuXrFwlxr5FvLtvOk1773lI9VXZfMItQIMR3Vm7mb7TvXykzEefqi9xYB99atZGXvPbbL4w387ZRbqyEb6/eyJpg+zu9i2ON3Dj6bFe+djNvhNqXT47WcmvxEgAe2byFA8F0PHX/uyrC9GgdHxznxnr45evbKA9G/P9fQYFF0aPcfNmbAfjVth3Ue+79i3/Q2B+r4e1jLgbg6d27iCN4JBBVAiTI2F3HrcVXE4tF2XZgGy13EHr+Vjbub4bi66irruJQ6esIiof661d2HlK48m1Ule4nfnADgnIkFyZOm97h/+FU9WnCF5HLgO8CAeDHqnpfKrbzxLLlfFY6diD2r9tWc8Wcc3h5y2ruDXfsAvjTuzdyyZyzeHLty3wrfUyH8rSK7Vw0dzF/XPEsD2SWIJogQBxPEwjKmZsOEJlzFn9c9Sw/yZiISvsWs8VSy4Lp03hk1XM8lDGhw/qvOeRx2vhx/GbN8zyeWdI6XdR9cD5Sm0dhXh6/2/ACT2VOaN2uRwJPE9yHS/jPvPEcy9JHu+n+xzqSaAJcQn9t1z/YGBmJ56c8QcmK17eWL9/7HFsjI/wl3aMwdhRwCf3F/S+xJ1zo1/BcbGWVla3lqw++wqFwngveP5rVl1fAvPe48sMrqQxmuy9Ny1evrJzErNtIaIIdR1bTEAi3bh1gS1k51VPfQUITlB1dQ0wCfrnbyNbDleydcBXNTY1kNryGR5yA//BIULujgU3jr6S6ooL5zctb94ugiCSI7YBlo95M+b5S3tq8wZ/u1xJJENsW5h95Z1G+cy/XNW93sUsCjwQBEjS8nsvjkZkc3baH24Jb/X2fwCOOJwlqXx/PL2Uy0W17uDN7Y1K52wdlW2byg+howtv28vmCja3Txf8/3L5hEauqc8jbUco9I7f4UbVE5/HKqln8aZ/H2H3VfHHkTv/9JwgQI0CCx5fP58HcOHMPVfO9UZv8vda2F77z/Gwq06OcWxnlG6N3J/3Pum1c87taagNNfCQ0i/NHH2qdroAoLHmkhjNHn8kFR6p4c8E+aF0zJGIB4FkArq/+Fjfm7U36ZCnx5jTgBQDeX3cfwZx9rdGBEmvKaS2/o+GLpAVL2/3fRhvHAG4Uss9HP0Mo3P6AGm2eBLiE/7X4JwiGqtuXN8wAXML/L/0wAa+hXXmidgHgEv5/BT6IeO3Ht/ZqzweuJoByX9pHOVa4/nLgOrKkma+k39GhPKPpRuBtFIUa+ULmZwAYHfy/DvP1hj7rHllEAsAbwFuBfcBrwC2quqmrZU62e+TffPctxGZ3rOXIG5mkl1XSlJNPYnadm5b0wYxtLMCraCBemE7ajMN+OXjqEuq+tTMoPZpLUWEN06etARVU/a+kCr9e/Q521Y3hrWNf47zT/wGSQMXVMlTgZy99kH0NI7hu0vPMOf2ldglLUL6/9ONUxfK4ccrfOaPkVUTbflYD3Lf6ehoCzbxz5OtMHbXNLa3+0ip8acc8QHlXbgWT8kvblUfjIb5VOglEuSW7inFZFW1bV6ExFuYHle5n8a1ZtYzOrKYlW4tAbVM6D1RnAcqHspsoiNS0Rg5Q1ZjB/9R5gPLRrDg5aY2tyVpEKavP5H/qmwHl07lCZrip9ZeNqrC/LosfNrh1fi4vRDgQJ/mTuasui583HgXgC/lBAl77z+3rR7P4TbQaSSh3FYRdqvTfe0JhY32YJ2M1ZKjH7TmhdrEDrKkP8Fy8jlwNcGtOWz2oZSuv1XssjzdQRJCbs712g1Qr8Gq9sD7RxEiCXJ4lbuAX2h7LGhLsTMQZKR7nprcMYt32d0WjcjihjPI85qS5ne7KXZPN+qYgNeoxKqBMDccR8fC0bezUNU0RGggw2oszKS1Ka1VA3IFhazSHKEEKAs0UBRrx8NyvN///d0e0kIQEGeXVMSJQj6cQ8oKEJULES+NQaBEZ4XxGxQ+Rq+WEvDAhCeMhVDWX80Ish81VKyhOHGJsENICGRRFiimKFFMYKSF9xK0AJGpfgdgBRDyQgPuGeelIlkuoiYaVEG8bN9Z9gDLxMpf45csgcRTEcw88xMtB0txob9q0HtVG2r45injZSHi6X74KTTS2loEigUIkPMOtv3EF0JLQ/UarQCESmuwvv8EvCuBOgXoQyEMCI9yoePF97ZYFwMtCvFxU4xA/3L4MAS8T8TJdeaIKgFAoj/NOG83JGBAjXonIOcA9qnqp//ouAFX9WlfLnGzCf+a86QRjnZcJ4hoK2j4P/leqFx2TqNu23VKsrdvsassJXFNCZ0RpHSi53Ua72F63pmn7wnbblvbT5JhtHbvODq+187ITLQfa5bInen2i9976XDubX0+4vmOX7+n2u/O6NyQ3XbTWqbv6YPWCmECTQJMHzUJrs9nJdqJ9bKitu3uI96jREBGu/EeXdeHjGij94Y8F9ia93gecdexMInI7cDvAhAkdmz26o+jsC9BotHUcWvX/oS2twv60pHL/Sdu84Lext518QhNoIg6JGKpx91zjkIij2r7NuWX5tu0nfViPabvXY54JEJIgaRIg7AUJS8A9/OchOd54UqegJV5t3Rmt0/CHK+xNJ9NzcnIIx8aj/kTtbH495jUd30/yvO3XoZ0s33PHLpuaqpYimgBNIBoH/9epe+3+ovGT2vfd1dL5tgLVxKkkRm1r6j8x6eI/prOD7FCl6R3Po/SGvkz4nX3EOvzXqeqDwIPgavgns6F53/rfk1nMGGOGtL68Dn8fMD7p9TjgQB9u3xhjhrW+TPivAaeLyCQRCQPvAJ7ow+0bY8yw1mdNOqoaE5GPAX/HncP5qapu7KvtG2PMcNen1+Gr6l+Bv/blNo0xxjjWl44xxgwTlvCNMWaYsIRvjDHDhCV8Y4wZJvqsa4WTISJlwO6TXLwIKD/hXAPTYI4dBnf8gzl2sPj700CJfaKqjuisYEAn/FMhIiu66k9ioBvMscPgjn8wxw4Wf38aDLFbk44xxgwTlvCNMWaYGMoJ/8H+DuAUDObYYXDHP5hjB4u/Pw342IdsG74xxpj2hnIN3xhjTBJL+MYYM0wMuYQvIpeJyOsisk1E/qO/4+kpEdklIutFZI2I9Hx8xz4mIj8VkcMisiFpWoGIPC0iW/2/+f0ZY1e6iP0eEdnv7/81InJFf8bYFREZLyLPishmEdkoInf40wfLvu8q/gG//0UkIiLLRWStH/uX/OkDft8PqTb8kxkofaARkV3AIlUdCDdwnJCIvAmoBX6pqrP8aV8HKlX1Pv+gm6+qn+nPODvTRez3ALWq+s3+jO1ERGQMMEZVV4lINrASuA54L4Nj33cV/80M8P0vIgJkqmqtiISAF4E7gOsZ4Pt+qNXwFwPbVHWHqjYDjwDX9nNMQ5qqPg9UHjP5WuAX/vNf4L7IA04XsQ8Kqlqqqqv85zXAZty40YNl33cV/4CnTq3/MuQ/lEGw74dawu9soPRB8SFKosBTIrLSH9B9MBqlqqXgvtjAyH6Op6c+JiLr/CafAfez/FgiUgLMB5YxCPf9MfHDINj/IhIQkTXAYeBpVR0U+36oJfxuDZQ+wJ2nqguAy4F/9ZsdTN/5H2AKMA8oBb7Vr9GcgIhkAY8Cd6rq0f6Op6c6iX9Q7H9VjavqPNzY3ItFZFY/h9QtQy3hD/qB0lX1gP/3MPA4rplqsDnkt9G2tNUe7ud4uk1VD/lf5gTwIwbw/vfbjx8FHlbVx/zJg2bfdxb/YNr/AKpaBSwFLmMQ7PuhlvAH9UDpIpLpn8BCRDKBS4ANx19qQHoCuM1/fhvwx36MpUdavrC+tzFA979/4vAnwGZV/XZS0aDY913FPxj2v4iMEJE8/3k6cDGwhUGw74fUVToA/mVc36FtoPR7+zei7hORybhaPbjxhn890OMXkd8AF+K6hj0E3A38AfgtMAHYA9ykqgPu5GgXsV+Ia05QYBfw4ZZ22YFERJYALwDrgYQ/+bO4dvDBsO+7iv8WBvj+F5E5uJOyAVyl+beq+mURKWSA7/shl/CNMcZ0bqg16RhjjOmCJXxjjBkmLOEbY8wwYQnfGGOGCUv4xhgzTFjCNyklIqNF5BER2S4im0TkryIytZ9julNEMk5iufeKSHHS6x+LyBm9G13f8N/LA/0dh+lblvBNyvg31zwOLFXVKap6Bu5a61H9Gxl3Ap0mfL/H1a68F2hN+Kr6wd7uiVVEgr25vqT1Hu99mWHCEr5JpTcDUVX9YcsEVV2jqi+I8w0R2SCu//+3A4jIhSKyVER+LyJbRORh/8CBiJwpIi/7/ZAvF5FsvxOrb4jIa36HWx8+3npE5BO4pP2siDzrz1srIl8WkWXAOSLyRX99G0TkQX+5G4FFwMPi+mlP99e/yF/HLf772CAi97e8X3/d9/oxvyoiHQ524vqAf1BEngJ+6d/J+agfw2sicp4/X5aI/MzfzjoRuaEb205+X+8TkTdE5DngvKT5bvKXXSsiz/fK/7wZmFTVHvZIyQP4BPBfXZTdADyNu1txFO7OxDG4O12rcf0gecArwBIgDOwAzvSXz8HdjXw78Hl/WhqwApjU1Xr8+XYBRUmxKHBz0uuCpOe/Aq72ny/FjVVA8mvcAWQPMMKP6Z/AdUnrbln+6y2xHrMv7sH1B5/uv/51UqwTcN0PANwPfCdpufxubPtm//mYpPnCwEvAA37ZemCs/zyvvz839kjdw2r4pr8sAX6jrqOsQ8BzwJl+2XJV3aeuA601QAkwDShV1dcAVPWoqsZw/Q29R1xXtcuAQuD046ynM3FcJ14t3iwiy0RkPfAWYOYJ3suZuGarMj+mh4GWXk6bgT/7z1ceJ4YnVLXBf34x8ID/np4AcsT1sXQx8IOWBVT1yAm2nfy+zkqarxn4v6RtvwT8XEQ+hDsAmyEqJe2Fxvg2Ajd2UdZZV9YtmpKex3GfU6Hzrq4F+Liq/r3dRJELu1hPZxpVNe4vFwH+G1eT3ytuBKzIcWJtiaErUVVtift4MdQlPfeAc5IOAPixdbYPjrft1vfl67QfFVX9FxE5C7gSWCMi81S14jjrNYOU1fBNKv0TSPNrjkBrO/wFwPPA2/02+BG4Wuny46xrC1AsImf668n2T3D+HfiIuK52EZGp4noaPZ4aILuLspbkXi6ur/bkA1ZXyy0DLhCRIv/k6C24Xywn6yngYy0vRGReF9Pze7DtZcCFIlLo76ubktYzRVWXqeoXgXLadzFuhhBL+CZl/Jrt24C3irsscyOuvfoA7uqddcBa3IHh06p68DjragbeDnxfRNbi2v8jwI+BTcAqcYOR/y8n/uX6IPBky0nbY7ZTheuHfT2u18/Xkop/Dvyw5aRt0jKlwF3As/77WaWqp9I17ieARf6J2U3Av/jTvwLkt5xgBd7c3W37892DO5fxDLAqqfgbLSd9cQfitacQuxnArLdMY4wZJqyGb4wxw4QlfGOMGSYs4RtjzDBhCd8YY4YJS/jGGDNMWMI3xphhwhK+McYME/8fhStUaclSxusAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainSequenceLSTM('train', train_sample_set, train_label_set, test_sample_set, test_label_set)\n",
    "model = keras.models.load_model('LSTM_MSE.h5')\n",
    "predict_set=model.predict(test_sample_set)\n",
    "plt.plot(conc_scaler.inverse_transform(test_label_set.reshape(test_label_set.shape[0],6)))\n",
    "plt.plot(conc_scaler.inverse_transform(np.mean(predict_set,axis=1)),linestyle='dashed')\n",
    "plt.title('Data-driven model')\n",
    "plt.xlabel('Concentration records')\n",
    "plt.ylabel('CO$_2$ composition(%)')\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(-0, 0.15)\n",
    "#plt.savefig('Data-driven.png',dpi=1000)\n",
    "print('MSE: ', mean_squared_error(conc_scaler.inverse_transform(test_label_set.reshape(test_label_set.shape[0],6)),\n",
    "                                  conc_scaler.inverse_transform(np.mean(predict_set,axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb10e5f",
   "metadata": {},
   "source": [
    "# Model fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb92183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinetic_model\\140206_1.csv  in test\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic_path_list = glob.glob('kinetic_model/1*.csv')\n",
    "def VAR_3D(xb,Y,H,B,R): #booleen=0 garde la trace\n",
    "    # xb: priori, Y: observation, H: obs. matrix, B: priori estimate uncertainty\n",
    "    # R: Measurement uncertainty\n",
    "    dim_x = xb.size\n",
    "    #dim_y = Y.size\n",
    "    Y.shape = (Y.size,1)\n",
    "    xb1=np.copy(xb)\n",
    "    xb1.shape=(xb1.size,1)\n",
    "    K=np.dot(B,np.dot(np.transpose(H),np.linalg.pinv(np.dot(H,np.dot(B,np.transpose(H)))+R))) #matrice de gain\n",
    "    \n",
    "    A=np.dot(np.dot((np.eye(dim_x)-np.dot(K,H)),B),np.transpose((np.eye(dim_x)-np.dot(K,H))))+np.dot(np.dot(K,R),np.transpose(K))\n",
    "    vect=np.dot(H,xb1)\n",
    "    xa=np.copy(xb1+np.dot(K,(Y-vect)))\n",
    "    return xa.ravel(),A\n",
    "\n",
    "test_name_list=[]\n",
    "for i in range(len(test_df_index_list)):\n",
    "    test_name_list.append(os.path.splitext(os.path.basename(data_path_list[test_df_index_list[i]]))[0])\n",
    "    \n",
    "dynamic_df_list=[]\n",
    "dynamic_train_list=[]\n",
    "dynamic_test_list=[]\n",
    "for path in dynamic_path_list:\n",
    "    dynamic_df_list.append(pd.read_csv(path, header=None))\n",
    "    if os.path.splitext(os.path.basename(path))[0] not in test_name_list:\n",
    "        dynamic_train_list.append(pd.read_csv(path, header=None))\n",
    "    else:\n",
    "        print(path, ' in test')\n",
    "        dynamic_test_list.append(pd.read_csv(path, header=None))\n",
    "\n",
    "for i in range(len(dynamic_train_list)):\n",
    "    if (i==0):\n",
    "        train_full_values=dynamic_train_list[i].values[callback:,:]\n",
    "    else:\n",
    "        train_full_values=np.concatenate((train_full_values, dynamic_train_list[i].values[callback:,:]), axis=0)\n",
    "B=np.cov((train_full_values*100-conc_scaler.inverse_transform(train_label_set.reshape(train_label_set.shape[0],6))).T)\n",
    "B=covLoc(B,2)\n",
    "np.save('B.npy',B)\n",
    "\n",
    "for i in range(len(dynamic_test_list)):\n",
    "    if (i==0):\n",
    "        test_full_values=dynamic_test_list[i].values[callback:,:]\n",
    "    else:\n",
    "        test_full_values=np.concatenate((test_full_values, dynamic_test_list[i].values[callback:,:]), axis=0)\n",
    "\n",
    "R=np.load('R.npy')\n",
    "B=np.load('B.npy')\n",
    "fig,axs=plt.subplots(nrows=1, ncols=2,sharey=True)\n",
    "axs[0].set_xticks(np.arange(0, 6, step=1))\n",
    "axs[1].set_xticks(np.arange(0, 6, step=1))\n",
    "#im1=axs[0].imshow(B,norm=LogNorm())\n",
    "#im2=axs[1].imshow(R,norm=LogNorm())\n",
    "im1=axs[0].imshow(B)\n",
    "axs[0].set_title('B')\n",
    "im2=axs[1].imshow(R)\n",
    "axs[1].set_title('R')\n",
    "cb=fig.colorbar(im1,ax=axs.ravel().tolist())\n",
    "#plt.savefig('cov.png',dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "H=np.eye(6)\n",
    "conc_set=test_full_values.copy()\n",
    "for i in range(conc_set.shape[0]):\n",
    "    conc_set[i],_ = VAR_3D(test_full_values[i]*100,conc_scaler.inverse_transform(np.mean(predict_set,axis=1))[i],H,B,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b369c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,3, sharey=True, figsize=(12,3))\n",
    "#plt.ylim(-0, 4.5)\n",
    "axs[0].plot(conc_scaler.inverse_transform(test_label_set.reshape(test_label_set.shape[0],6)))\n",
    "axs[0].plot(test_full_values*100,linestyle='dashed')\n",
    "axs[0].set_title('Kinetic model')\n",
    "axs[0].set_ylabel('CO$_2$ composition(%)')\n",
    "axs[0].set_xlabel('Records')\n",
    "axs[1].plot(conc_scaler.inverse_transform(test_label_set.reshape(test_label_set.shape[0],6)))\n",
    "axs[1].plot(conc_scaler.inverse_transform(np.mean(predict_set,axis=1)),linestyle='dashed')\n",
    "axs[1].set_title('Data-driven model')\n",
    "axs[1].set_xlabel('Records')\n",
    "axs[2].plot(conc_scaler.inverse_transform(test_label_set.reshape(test_label_set.shape[0],6)))\n",
    "axs[2].plot(conc_set,linestyle='dashed')\n",
    "axs[2].set_title('Fused model')\n",
    "axs[2].set_xlabel('Records')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('compare_set1.png',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92e058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
